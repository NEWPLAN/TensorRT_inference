

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tensorrt.infer &mdash; TensorRT 4.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  <link rel="stylesheet" href="../_static/css/tensorrt_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="tensorrt.utils" href="utils.html" />
    <link rel="prev" title="Manually Constructing a TensorRT Engine" href="../workflows/manually_construct_tensorrt_engine.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> TensorRT
          

          
            
            <img src="../_static/nvlogo.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                4.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Graph Surgeon API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../graphsurgeon/graphsurgeon.html">Graph Surgeon</a></li>
</ul>
<p class="caption"><span class="caption-text">UFF API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../uff/uff.html">UFF</a></li>
</ul>
<p class="caption"><span class="caption-text">Workflows</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../workflows/caffe_to_tensorrt.html">Using TensorRT to Optimize Caffe Models in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../workflows/tf_to_tensorrt.html">Generating TensorRT Engines from TensorFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../workflows/manually_construct_tensorrt_engine.html">Manually Constructing a TensorRT Engine</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">tensorrt.infer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#foundational-types">Foundational Types</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#datatype">DataType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#weights">Weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dims">Dims</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dimshw">DimsHW</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dimschw">DimsCHW</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dimsnchw">DimsNCHW</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dimensiontype">DimensionType</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#engine-and-inference">Engine and Inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#builder">Builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-infer-builder">create_infer_builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cudaengine">CudaEngine</a></li>
<li class="toctree-l3"><a class="reference internal" href="#executioncontext">ExecutionContext</a></li>
<li class="toctree-l3"><a class="reference internal" href="#runtime">Runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-infer-runtime">create_infer_runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hostmemory">HostMemory</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#graph-definition">Graph Definition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#networkdefinition">NetworkDefinition</a></li>
<li class="toctree-l3"><a class="reference internal" href="#layertype">LayerType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tensor">Tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#layer">Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#convolutionlayer">ConvolutionLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fullyconnectedlayer">FullyConnectedLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationlayer">ActivationLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationtype">ActivationType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#poolinglayer">PoolingLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#poolingtype">PoolingType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lrnlayer">LRNLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scalelayer">ScaleLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scalemode">ScaleMode</a></li>
<li class="toctree-l3"><a class="reference internal" href="#softmaxlayer">SoftmaxLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concatenationlayer">ConcatenationLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deconvolutionlayer">DeconvolutionLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#elementwiselayer">ElementWiseLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#elementwiseoperation">ElementWiseOperation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#shufflelayer">ShuffleLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#permutation">Permutation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#unarylayer">UnaryLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#unaryoperation">UnaryOperation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pluginlayer">PluginLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#paddinglayer">PaddingLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rnnlayer">RNNLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rnnoperation">RNNOperation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rnndirection">RNNDirection</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rnninputmode">RNNInputMode</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#int8-calibration">Int8 Calibration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#int8calibrator">Int8Calibrator</a></li>
<li class="toctree-l3"><a class="reference internal" href="#int8entropycalibrator">Int8EntropyCalibrator</a></li>
<li class="toctree-l3"><a class="reference internal" href="#int8legacycalibrator">Int8LegacyCalibrator</a></li>
<li class="toctree-l3"><a class="reference internal" href="#calibrationalgotype">CalibrationAlgoType</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#logger">Logger</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Logger</a></li>
<li class="toctree-l3"><a class="reference internal" href="#consolelogger">ConsoleLogger</a></li>
<li class="toctree-l3"><a class="reference internal" href="#logseverity">LogSeverity</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#profiler">Profiler</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">Profiler</a></li>
<li class="toctree-l3"><a class="reference internal" href="#consoleprofiler">ConsoleProfiler</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">tensorrt.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="lite.html">tensorrt.lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="parsers.html">tensorrt.parsers</a></li>
</ul>
<p class="caption"><span class="caption-text">Index</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">Index</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">TensorRT</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>tensorrt.infer</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/pkg_ref/infer.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

/* nice headers on first paragraph of info/warning boxes */
.admonition .first {
    margin: -12px;
    padding: 6px 12px;
    margin-bottom: 12px;
    color: #fff;
    line-height: 1;
    display: block;
}
.admonition.warning .first {
    background: #f0b37e;
}
.admonition.note .first {
    background: #6ab0de;
}
.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="section" id="tensorrt-infer">
<h1>tensorrt.infer<a class="headerlink" href="#tensorrt-infer" title="Permalink to this headline">¶</a></h1>
<p>The <code class="xref py py-mod docutils literal notranslate"><span class="pre">infer</span></code> package contains an interface for libnvinfer. This module is used for graph definition,
engine building and inference execution.</p>
<span class="target" id="module-tensorrt.infer"></span><div class="section" id="foundational-types">
<h2>Foundational Types<a class="headerlink" href="#foundational-types" title="Permalink to this headline">¶</a></h2>
<div class="section" id="datatype">
<h3>DataType<a class="headerlink" href="#datatype" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.DataType">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">DataType</code><a class="headerlink" href="#tensorrt.infer.DataType" title="Permalink to this definition">¶</a></dt>
<dd><p>Available data types</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="weights">
<h3>Weights<a class="headerlink" href="#weights" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Weights">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Weights</code><a class="headerlink" href="#tensorrt.infer.Weights" title="Permalink to this definition">¶</a></dt>
<dd><p>An array of weights used as a layer parameter.</p>
<p>The weights are held by reference until the engine has been built. Therefore the data referenced by <cite>values</cite> field should be preserved until the build is complete.</p>
<dl class="attribute">
<dt>
<code class="descname">* `type`</code></dt>
<dd><p><cite>DataType</cite> – The type of the weights.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">* `values`</code></dt>
<dd><p><cite>const void *</cite> – The weight values, in a contiguous array.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">* `count`</code></dt>
<dd><p><cite>int64_t</cite> – The number of weights in the array.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">C++ includes</code></dt>
<dd><p><em>NvInfer.h</em></p>
</dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.Weights.count">
<code class="descname">count</code><a class="headerlink" href="#tensorrt.infer.Weights.count" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.Weights.type">
<code class="descname">type</code><a class="headerlink" href="#tensorrt.infer.Weights.type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.Weights.values">
<code class="descname">values</code><a class="headerlink" href="#tensorrt.infer.Weights.values" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="dims">
<h3>Dims<a class="headerlink" href="#dims" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Dims">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Dims</code><a class="headerlink" href="#tensorrt.infer.Dims" title="Permalink to this definition">¶</a></dt>
<dd><p>Structure to define the dimensions of a tensor.</p>
<p>note: : Currently the following formats are supported for layer inputs and outputs:</p>
<blockquote>
<div><ul class="simple">
<li>zero or more index dimensions followed by one channel and two spatial dimensions (e.g. CHW)</li>
<li>one time series dimension followed by one index dimension followed by one channel dimension (i.e. TNC)</li>
</ul>
</div></blockquote>
<dl class="attribute">
<dt>
<code class="descname">* `MAX_DIMS`</code></dt>
<dd><p><cite>const int</cite> – The maximum number of dimensions supported for a tensor.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">* `nbDims`</code></dt>
<dd><p><cite>int</cite> – The number of dimensions.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">* `d`</code></dt>
<dd><p><cite>int</cite> – The extent of each dimension.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">* `type`</code></dt>
<dd><p><cite>DimensionType</cite> – The type of each dimension.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">C++ includes</code></dt>
<dd><p><em>NvInfer.h</em></p>
</dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.Dims.d">
<code class="descname">d</code><a class="headerlink" href="#tensorrt.infer.Dims.d" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.Dims.nbDims">
<code class="descname">nbDims</code><a class="headerlink" href="#tensorrt.infer.Dims.nbDims" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.Dims.type">
<code class="descname">type</code><a class="headerlink" href="#tensorrt.infer.Dims.type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="dimshw">
<h3>DimsHW<a class="headerlink" href="#dimshw" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.DimsHW">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">DimsHW</code><a class="headerlink" href="#tensorrt.infer.DimsHW" title="Permalink to this definition">¶</a></dt>
<dd><p>Descriptor for two-dimensional spatial data.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.DimsHW.h">
<code class="descname">h</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsHW.h" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">h()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the height.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The height.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DimsHW.w">
<code class="descname">w</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsHW.w" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">w()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the width.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The width.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="dimschw">
<h3>DimsCHW<a class="headerlink" href="#dimschw" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.DimsCHW">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">DimsCHW</code><a class="headerlink" href="#tensorrt.infer.DimsCHW" title="Permalink to this definition">¶</a></dt>
<dd><p>Descriptor for data with one channel dimension and two spatial dimensions.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.DimsCHW.c">
<code class="descname">c</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsCHW.c" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">c()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the channel count.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The channel count.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DimsCHW.h">
<code class="descname">h</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsCHW.h" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">h()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the height.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The height.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DimsCHW.w">
<code class="descname">w</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsCHW.w" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">w()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the width.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The width.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="dimsnchw">
<h3>DimsNCHW<a class="headerlink" href="#dimsnchw" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.DimsNCHW">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">DimsNCHW</code><a class="headerlink" href="#tensorrt.infer.DimsNCHW" title="Permalink to this definition">¶</a></dt>
<dd><p>Descriptor for data with one index dimension, one channel dimension and two spatial dimensions.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.DimsNCHW.c">
<code class="descname">c</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsNCHW.c" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">c()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the channel count.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The channel count.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DimsNCHW.h">
<code class="descname">h</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsNCHW.h" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">h()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the height.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The height.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DimsNCHW.n">
<code class="descname">n</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsNCHW.n" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">n()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the index count.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The index count.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DimsNCHW.w">
<code class="descname">w</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsNCHW.w" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">w()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the width.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The width.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="dimensiontype">
<h3>DimensionType<a class="headerlink" href="#dimensiontype" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.DimensionType">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">DimensionType</code><a class="headerlink" href="#tensorrt.infer.DimensionType" title="Permalink to this definition">¶</a></dt>
<dd><p>Available dimension types</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
</div>
<div class="section" id="engine-and-inference">
<h2>Engine and Inference<a class="headerlink" href="#engine-and-inference" title="Permalink to this headline">¶</a></h2>
<div class="section" id="builder">
<h3>Builder<a class="headerlink" href="#builder" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Builder">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Builder</code><a class="headerlink" href="#tensorrt.infer.Builder" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds an engine from a network definition.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Builder.build_cuda_engine">
<code class="descname">build_cuda_engine</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.build_cuda_engine" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">buildCudaEngine(nvinfer1::INetworkDefinition</span> <span class="pre">&amp;network)=0</span> <span class="pre">-&gt;</span> <span class="pre">nvinfer1::ICudaEngine</span> <span class="pre">*</span></code></p>
<p>Build a CUDA engine from a network definition.</p>
<p>See also: INetworkDefinition ICudaEngine</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.create_network">
<code class="descname">create_network</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.create_network" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">createNetwork()=0</span> <span class="pre">-&gt;</span> <span class="pre">nvinfer1::INetworkDefinition</span> <span class="pre">*</span></code></p>
<p>Create a network definition object.</p>
<p>See also: INetworkDefinition</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.destroy">
<code class="descname">destroy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.destroy" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">destroy()=0</span></code></p>
<p>Destroy this object.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_average_find_iterations">
<code class="descname">get_average_find_iterations</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_average_find_iterations" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getAverageFindIterations()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Query the number of averaging iterations.</p>
<p>See also: setAverageFindIterations()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_debug_sync">
<code class="descname">get_debug_sync</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_debug_sync" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getDebugSync()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Query whether the builder will use debug synchronization.</p>
<p>See also: setDebugSync()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_fp16_mode">
<code class="descname">get_fp16_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_fp16_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getFp16Mode()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Query whether 16-bit kernels are permitted.</p>
<p>See also: setFp16Mode()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_half2_mode">
<code class="descname">get_half2_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_half2_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getHalf2Mode()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Query whether half2 mode is used.</p>
<p>See also: setHalf2Mode()
Deprecated
This function is superseded by getFp16Mode.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_int8_mode">
<code class="descname">get_int8_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_int8_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getInt8Mode()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Query whether Int8 mode is used.</p>
<p>See also: setInt8Mode()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_max_batch_size">
<code class="descname">get_max_batch_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_max_batch_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getMaxBatchSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the maximum batch size.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The maximum batch size.</em></li>
<li><strong>See also</strong> (<em>setMaxBatchSize()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_max_workspace_size">
<code class="descname">get_max_workspace_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_max_workspace_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getMaxWorkspaceSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">std::size_t</span></code></p>
<p>Get the maximum workspace size.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The maximum workspace size.</em></li>
<li><strong>See also</strong> (<em>setMaxWorkspaceSize()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_min_find_iterations">
<code class="descname">get_min_find_iterations</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_min_find_iterations" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getMinFindIterations()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Query the number of minimzation iterations.</p>
<p>See also: setMinFindIterations()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.platform_has_fast_fp16">
<code class="descname">platform_has_fast_fp16</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.platform_has_fast_fp16" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">platformHasFastFp16()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Determine whether the platform has fast native fp16.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.platform_has_fast_int8">
<code class="descname">platform_has_fast_int8</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.platform_has_fast_int8" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">platformHasFastInt8()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Determine whether the platform has fast native int8.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_average_find_iterations">
<code class="descname">set_average_find_iterations</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_average_find_iterations" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setAverageFindIterations(int</span> <span class="pre">avgFind)=0</span></code></p>
<p>Set the number of minimization iterations used when timing layers.</p>
<p>When timing layers, the builder minimizes over a set of average times for layer execution. This parameter controls the number of iterations used in averaging.</p>
<p>See also: getAverageFindIterations()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_debug_sync">
<code class="descname">set_debug_sync</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_debug_sync" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setDebugSync(bool</span> <span class="pre">sync)=0</span></code></p>
<p>Set whether the builder should use debug synchronization.</p>
<p>If this flag is true, the builder will synchronize after timing each layer, and report the layer name. It can be useful when diagnosing issues at build time.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_fp16_mode">
<code class="descname">set_fp16_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_fp16_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setFp16Mode(bool</span> <span class="pre">mode)=0</span></code></p>
<p>Set whether or not 16-bit kernels are permitted.</p>
<p>During engine build fp16 kernels will also be tried when this mode is enabled.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>mode</strong> (<em>*</em>) – Whether 16-bit kernels are permitted.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_gpu_allocator">
<code class="descname">set_gpu_allocator</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_gpu_allocator" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setGpuAllocator(IGpuAllocator</span> <span class="pre">*allocator)=0</span></code></p>
<p>Set the GPU allocator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>allocator</strong> (<em>*</em>) – Set the GPU allocator to be used by the builder. All GPU memory acquired will use this allocator. If NULL is passed, the default allocator will be used.</li>
<li><strong>Default</strong> (<em>uses cudaMalloc/cudaFree.</em>) – </li>
<li><strong>note</strong> (<em>This allocator will be passed to any engines created via the builder; thus the lifetime of the allocator must span the lifetime of those engines as well as that of the builder. If nullptr is</em>) – passed, the default allocator will be used.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_half2_mode">
<code class="descname">set_half2_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_half2_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setHalf2Mode(bool</span> <span class="pre">mode)=0</span></code></p>
<p>Set whether half2 mode is used.</p>
<p>half2 mode is a paired-image mode that is significantly faster for batch sizes greater than one on platforms with fp16 support.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>mode</strong> (<em>*</em>) – Whether half2 mode is used.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
<li><strong>Deprecated</strong> – </li>
<li><strong>function is superseded by setFp16Mode.</strong> (<em>This</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_int8_calibrator">
<code class="descname">set_int8_calibrator</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_int8_calibrator" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setInt8Calibrator(IInt8Calibrator</span> <span class="pre">*calibrator)=0</span></code></p>
<p>Set Int8 Calibration interface.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_int8_mode">
<code class="descname">set_int8_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_int8_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setInt8Mode(bool</span> <span class="pre">mode)=0</span></code></p>
<p>Set the maximum value for a region.</p>
<p>Used for INT8 mode compression.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_max_batch_size">
<code class="descname">set_max_batch_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_max_batch_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setMaxBatchSize(int</span> <span class="pre">batchSize)=0</span></code></p>
<p>Set the maximum batch size.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>batchSize</strong> (<em>*</em>) – The maximum batch size which can be used at execution time, and also the batch size for which the engine will be optimized.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_max_workspace_size">
<code class="descname">set_max_workspace_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_max_workspace_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setMaxWorkspaceSize(std::size_t</span> <span class="pre">workspaceSize)=0</span></code></p>
<p>Set the maximum workspace size.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>workspaceSize</strong> (<em>*</em>) – The maximum GPU temporary memory which the engine can use at execution time.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_min_find_iterations">
<code class="descname">set_min_find_iterations</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_min_find_iterations" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setMinFindIterations(int</span> <span class="pre">minFind)=0</span></code></p>
<p>Set the number of minimization iterations used when timing layers.</p>
<p>When timing layers, the builder minimizes over a set of average times for layer execution. This parameter controls the number of iterations used in minimzation.</p>
<p>See also: getMinFindIterations()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="create-infer-builder">
<h3>create_infer_builder<a class="headerlink" href="#create-infer-builder" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="tensorrt.infer.create_infer_builder">
<code class="descclassname">tensorrt.infer.</code><code class="descname">create_infer_builder</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.create_infer_builder" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="cudaengine">
<h3>CudaEngine<a class="headerlink" href="#cudaengine" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.CudaEngine">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">CudaEngine</code><a class="headerlink" href="#tensorrt.infer.CudaEngine" title="Permalink to this definition">¶</a></dt>
<dd><p>An engine for executing inference on a built network.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.CudaEngine.binding_is_input">
<code class="descname">binding_is_input</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.binding_is_input" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">bindingIsInput(int</span> <span class="pre">bindingIndex)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Determine whether a binding is an input binding.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>bindingIndex</strong> (<em>*</em>) – The binding index.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>True if the index corresponds to an input binding and the index is in range.</em></li>
<li><strong>See also</strong> (<em>getBindingIndex()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.create_execution_context">
<code class="descname">create_execution_context</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.create_execution_context" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">createExecutionContext()=0</span> <span class="pre">-&gt;</span> <span class="pre">IExecutionContext</span> <span class="pre">*</span></code></p>
<p>Create an execution context.</p>
<p>See also: IExecutionContext.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.create_execution_context_without_device_memory">
<code class="descname">create_execution_context_without_device_memory</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.create_execution_context_without_device_memory" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">createExecutionContextWithoutDeviceMemory()=0</span> <span class="pre">-&gt;</span> <span class="pre">IExecutionContext</span> <span class="pre">*</span></code></p>
<p>create an execution context without any device memory allocated</p>
<p>The memory for execution of this device context must be supplied by the application.</p>
<p>See also: getDeviceMemorySize() IExecutionContext::setDeviceMemory()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.destroy">
<code class="descname">destroy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.destroy" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">destroy()=0</span></code></p>
<p>Destroy this object;.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_binding_data_type">
<code class="descname">get_binding_data_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_binding_data_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getBindingDataType(int</span> <span class="pre">bindingIndex)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DataType</span></code></p>
<p>Determine the required data type for a buffer from its binding index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>bindingIndex</strong> (<em>*</em>) – The binding index.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The type of the data in the buffer.</em></li>
<li><strong>See also</strong> (<em>getBindingIndex()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_binding_dimensions">
<code class="descname">get_binding_dimensions</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_binding_dimensions" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getBindingDimensions(int</span> <span class="pre">bindingIndex)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Dims</span></code></p>
<p>Get the dimensions of a binding.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>bindingIndex</strong> (<em>*</em>) – The binding index.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The dimensions of the binding if the index is in range, otherwise (0,0,0).</em></li>
<li><strong>See also</strong> (<em>getBindingIndex()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_binding_index">
<code class="descname">get_binding_index</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_binding_index" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getBindingIndex(const</span> <span class="pre">char</span> <span class="pre">*name)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Retrieve the binding index for a named tensor.</p>
<p>IExecutionContext::enqueue() and IExecutionContext::execute() require an array of buffers.</p>
<p>Engine bindings map from tensor names to indices in this array. Binding indices are assigned at engine build time, and take values in the range [0 … n-1] where n is the total number of inputs and
outputs.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>name</strong> (<em>*</em>) – The tensor name.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The binding index for the named tensor, or -1 if the name is not found.</em></li>
<li><em>see getNbBindings() getBindingIndex()</em></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_binding_name">
<code class="descname">get_binding_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_binding_name" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getBindingName(int</span> <span class="pre">bindingIndex)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">const</span> <span class="pre">char</span> <span class="pre">*</span></code></p>
<p>Retrieve the name corresponding to a binding index.</p>
<p>This is the reverse mapping to that provided by getBindingIndex().</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>bindingIndex</strong> (<em>*</em>) – The binding index.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The name corresponding to the index, or nullptr if the index is out of range.</em></li>
<li><strong>See also</strong> (<em>getBindingIndex()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_device_memory_size">
<code class="descname">get_device_memory_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_device_memory_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getDeviceMemorySize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">size_t</span></code></p>
<p>Return the amount of device memory required by an execution context.</p>
<p>See also: IExecutionContext::setDeviceMemory()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_location">
<code class="descname">get_location</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_location" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getLocation(int</span> <span class="pre">bindingIndex)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">TensorLocation</span></code></p>
<p>Get location of binding.</p>
<p>This lets you know whether the binding should be a pointer to device or host memory.</p>
<p>See also: ITensor::setLocation() ITensor::getLocation()</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>bindingIndex</strong> (<em>*</em>) – The binding index.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">The location of the bound tensor with given index.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_max_batch_size">
<code class="descname">get_max_batch_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_max_batch_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getMaxBatchSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the maximum batch size which can be used for inference.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The maximum batch size for this engine.</em></li>
<li><strong>See also</strong> (<em>getBindingIndex()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_nb_bindings">
<code class="descname">get_nb_bindings</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_nb_bindings" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getNbBindings()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the number of binding indices.</p>
<p>See also: getBindingIndex();</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_nb_layers">
<code class="descname">get_nb_layers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_nb_layers" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getNbLayers()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the number of layers in the network.</p>
<p>The number of layers in the network is not necessarily the number in the original network definition, as layers may be combined or eliminated as the engine is optimized. This value can be useful when
building per-layer tables, such as when aggregating profiling data over a number of executions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The number of layers in the network.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_workspace_size">
<code class="descname">get_workspace_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_workspace_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getWorkspaceSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">std::size_t</span></code></p>
<p>Get the amount of workspace the engine uses.</p>
<p>The workspace size will be no greater than the value provided to the builder when the engine was built, and will typically be smaller. Workspace will be allocated for each execution context.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.serialize">
<code class="descname">serialize</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.serialize" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">serialize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">IHostMemory</span> <span class="pre">*</span></code></p>
<p>Serialize the network to a stream.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>A IHostMemory object that contains the serialized engine.</em></li>
<li><em>The network may be deserialized with IRuntime::deserializeCudaEngine()</em></li>
<li><strong>See also</strong> (<em>IRuntime::deserializeCudaEngine()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="executioncontext">
<h3>ExecutionContext<a class="headerlink" href="#executioncontext" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ExecutionContext">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ExecutionContext</code><a class="headerlink" href="#tensorrt.infer.ExecutionContext" title="Permalink to this definition">¶</a></dt>
<dd><p>Context for executing inference using an engine.</p>
<p>Multiple execution contexts may exist for one ICudaEngine instance, allowing the same engine to be used for the execution of multiple batches simultaneously.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.destroy">
<code class="descname">destroy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.destroy" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">destroy()=0</span></code></p>
<p>Destroy this object.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.enqueue">
<code class="descname">enqueue</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.enqueue" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">enqueue(int</span> <span class="pre">batchSize,</span> <span class="pre">void</span> <span class="pre">**bindings,</span> <span class="pre">cudaStream_t</span> <span class="pre">stream,</span> <span class="pre">cudaEvent_t</span> <span class="pre">*inputConsumed)=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Asynchronously execute inference on a batch.</p>
<p>This method requires a array of input and output buffers. The mapping from tensor names to indices can be queried using ICudaEngine::getBindingIndex()</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>batchSize</strong> (<em>*</em>) – The batch size. This is at most the value supplied when the engine was built.</li>
<li><strong>bindings</strong> (<em>*</em>) – An array of pointers to input and output buffers for the network.</li>
<li><strong>stream</strong> (<em>*</em>) – A cuda stream on which the inference kernels will be enqueued</li>
<li><strong>inputConsumed</strong> (<em>*</em>) – An optional event which will be signaled when the input buffers can be refilled with new data</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>True if the kernels were enqueued successfully.</em></li>
<li><strong>See also</strong> (<em>ICudaEngine::getBindingIndex() ICudaEngine::getMaxBatchSize()</em>)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.execute">
<code class="descname">execute</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.execute" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">execute(int</span> <span class="pre">batchSize,</span> <span class="pre">void</span> <span class="pre">**bindings)=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Synchronously execute inference on a batch.</p>
<p>This method requires a array of input and output buffers. The mapping from tensor names to indices can be queried using ICudaEngine::getBindingIndex()</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>batchSize</strong> (<em>*</em>) – The batch size. This is at most the value supplied when the engine was built.</li>
<li><strong>bindings</strong> (<em>*</em>) – An array of pointers to input and output buffers for the network.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>True if execution succeeded.</em></li>
<li><strong>See also</strong> (<em>ICudaEngine::getBindingIndex() ICudaEngine::getMaxBatchSize()</em>)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.get_debug_sync">
<code class="descname">get_debug_sync</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.get_debug_sync" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getDebugSync()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Get the debug sync flag.</p>
<p>See also: setDebugSync()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.get_engine">
<code class="descname">get_engine</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.get_engine" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getEngine()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">const</span> <span class="pre">ICudaEngine</span> <span class="pre">&amp;</span></code></p>
<p>Get the associated engine.</p>
<p>See also: ICudaEngine</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.get_name">
<code class="descname">get_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.get_name" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getName()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">const</span> <span class="pre">char</span> <span class="pre">*</span></code></p>
<p>Return the name of the execution context.</p>
<p>See also: setName()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.get_profiler">
<code class="descname">get_profiler</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.get_profiler" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getProfiler()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">IProfiler</span> <span class="pre">*</span></code></p>
<p>Get the profiler.</p>
<p>See also: IProfiler setProfiler()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.set_debug_sync">
<code class="descname">set_debug_sync</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.set_debug_sync" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setDebugSync(bool</span> <span class="pre">sync)=0</span></code></p>
<p>Set the debug sync flag.</p>
<p>If this flag is set to true, the engine will log the successful execution for each kernel during execute(). It has no effect when using enqueue().</p>
<p>See also: getDebugSync()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.set_device_memory">
<code class="descname">set_device_memory</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.set_device_memory" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setDeviceMemory(void</span> <span class="pre">*memory)=0</span></code></p>
<p>set the device memory for use by this execution context.</p>
<p>The memory must be aligned on a 256-byte boundary, and its size must be at least that returned by getDeviceMemorySize(). If using enqueue() to run the network, The memory is in use from the invocation
of enqueue() until network execution is complete. If using execute(), it is in use until execute() returns. Releasing or otherwise using the memory for other purposes during this time will result in
undefined behavior.</p>
<p>See also: ICudaEngine::getDeviceMemorySize() ICudaEngine::createExecutionContextWithoutDeviceMemory()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.set_name">
<code class="descname">set_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.set_name" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setName(const</span> <span class="pre">char</span> <span class="pre">*name)=0</span></code></p>
<p>Set the name of the execution context.</p>
<p>This method copies the name string.</p>
<p>See also: getName()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.set_profiler">
<code class="descname">set_profiler</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.set_profiler" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setProfiler(IProfiler</span> <span class="pre">*)=0</span></code></p>
<p>Set the profiler.</p>
<p>See also: IProfiler getProfiler()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="runtime">
<h3>Runtime<a class="headerlink" href="#runtime" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Runtime">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Runtime</code><a class="headerlink" href="#tensorrt.infer.Runtime" title="Permalink to this definition">¶</a></dt>
<dd><p>Allows a serialized engine to be deserialized.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Runtime.deserialize_cuda_engine">
<code class="descname">deserialize_cuda_engine</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Runtime.deserialize_cuda_engine" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">deserializeCudaEngine(const</span> <span class="pre">void</span> <span class="pre">*blob,</span> <span class="pre">std::size_t</span> <span class="pre">size,</span> <span class="pre">IPluginFactory</span> <span class="pre">*pluginFactory)=0</span> <span class="pre">-&gt;</span> <span class="pre">nvinfer1::ICudaEngine</span> <span class="pre">*</span></code></p>
<p>Deserialize an engine from a stream.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>blob</strong> (<em>*</em>) – The memory that holds the serialized engine.</li>
<li><strong>size</strong> (<em>*</em>) – The size of the memory.</li>
<li><strong>pluginFactory</strong> (<em>*</em>) – The plugin factory, if any plugins are used by the network, otherwise nullptr.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The engine, or nullptr if it could not be deserialized.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Runtime.destroy">
<code class="descname">destroy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Runtime.destroy" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">destroy()=0</span></code></p>
<p>Destroy this object.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Runtime.set_gpu_allocator">
<code class="descname">set_gpu_allocator</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Runtime.set_gpu_allocator" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setGpuAllocator(IGpuAllocator</span> <span class="pre">*allocator)=0</span></code></p>
<p>Set the GPU allocator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>allocator</strong> (<em>*</em>) – Set the GPU allocator to be used by the runtime. All GPU memory acquired will use this allocator. If NULL is passed, the default allocator will be used.</li>
<li><strong>Default</strong> (<em>uses cudaMalloc/cudaFree.</em>) – </li>
<li><strong>nullptr is passed</strong><strong>, </strong><strong>the default allocator will be used.</strong> (<em>If</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="create-infer-runtime">
<h3>create_infer_runtime<a class="headerlink" href="#create-infer-runtime" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="tensorrt.infer.create_infer_runtime">
<code class="descclassname">tensorrt.infer.</code><code class="descname">create_infer_runtime</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.create_infer_runtime" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="hostmemory">
<h3>HostMemory<a class="headerlink" href="#hostmemory" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.HostMemory">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">HostMemory</code><a class="headerlink" href="#tensorrt.infer.HostMemory" title="Permalink to this definition">¶</a></dt>
<dd><p>Class to handle library allocated memory that is accessible to the user.</p>
<p>The memory allocated via the host memory object is owned by the library and will be de-allocated when the destroy method is called.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.HostMemory.data">
<code class="descname">data</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.HostMemory.data" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">data()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">void</span> <span class="pre">*</span></code></p>
<p>A pointer to the raw data that is owned by the library.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.HostMemory.destroy">
<code class="descname">destroy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.HostMemory.destroy" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">destroy()=0</span></code></p>
<p>Destroy the allocated memory.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.HostMemory.size">
<code class="descname">size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.HostMemory.size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">size()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">std::size_t</span></code></p>
<p>The size in bytes of the data that was allocated.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.HostMemory.type">
<code class="descname">type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.HostMemory.type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">type()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DataType</span></code></p>
<p>The type of the memory that was allocated.</p>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="graph-definition">
<h2>Graph Definition<a class="headerlink" href="#graph-definition" title="Permalink to this headline">¶</a></h2>
<div class="section" id="networkdefinition">
<h3>NetworkDefinition<a class="headerlink" href="#networkdefinition" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.NetworkDefinition">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">NetworkDefinition</code><a class="headerlink" href="#tensorrt.infer.NetworkDefinition" title="Permalink to this definition">¶</a></dt>
<dd><p>A network definition for input to the builder.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_activation">
<code class="descname">add_activation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_activation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addActivation(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">ActivationType</span> <span class="pre">type)=0</span> <span class="pre">-&gt;</span> <span class="pre">IActivationLayer</span> <span class="pre">*</span></code></p>
<p>Add an activation layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – The input tensor to the layer.</li>
<li><strong>type</strong> (<em>*</em>) – The type of activation function to apply.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new activation layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_concatenation">
<code class="descname">add_concatenation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_concatenation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addConcatenation(ITensor</span> <span class="pre">*const</span> <span class="pre">*inputs,</span> <span class="pre">int</span> <span class="pre">nbInputs)=0</span> <span class="pre">-&gt;</span> <span class="pre">IConcatenationLayer</span> <span class="pre">*</span></code></p>
<p>Add a concatenation layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> (<em>*</em>) – The input tensors to the layer.</li>
<li><strong>nbInputs</strong> (<em>*</em>) – The number of input tensors.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>The new concatenation layer, or null if it could not be created.</em></li>
<li><strong>**Warning**</strong> (<em>All tensors must have the same dimensions for all dimensions except for channel.</em>)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_constant">
<code class="descname">add_constant</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_constant" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addConstant(Dims</span> <span class="pre">dimensions,</span> <span class="pre">Weights</span> <span class="pre">weights)=0</span> <span class="pre">-&gt;</span> <span class="pre">IConstantLayer</span> <span class="pre">*</span></code></p>
<p>Add a constant layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dimensions</strong> (<em>*</em>) – The dimensions of the constant.</li>
<li><strong>weights</strong> (<em>*</em>) – The constant value, represented as weights.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new constant layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_convolution">
<code class="descname">add_convolution</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_convolution" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addConvolution(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">int</span> <span class="pre">nbOutputMaps,</span> <span class="pre">DimsHW</span> <span class="pre">kernelSize,</span> <span class="pre">Weights</span> <span class="pre">kernelWeights,</span> <span class="pre">Weights</span> <span class="pre">biasWeights)=0</span> <span class="pre">-&gt;</span> <span class="pre">IConvolutionLayer</span> <span class="pre">*</span></code></p>
<p>Add a convolution layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – The input tensor to the convolution.</li>
<li><strong>nbOutputMaps</strong> (<em>*</em>) – The number of output feature maps for the convolution.</li>
<li><strong>kernelSize</strong> (<em>*</em>) – The HW-dimensions of the convolution kernel.</li>
<li><strong>kernelWeights</strong> (<em>*</em>) – The kernel weights for the convolution.</li>
<li><strong>biasWeights</strong> (<em>*</em>) – The optional bias weights for the convolution.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new convolution layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_deconvolution">
<code class="descname">add_deconvolution</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_deconvolution" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addDeconvolution(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">int</span> <span class="pre">nbOutputMaps,</span> <span class="pre">DimsHW</span> <span class="pre">kernelSize,</span> <span class="pre">Weights</span> <span class="pre">kernelWeights,</span> <span class="pre">Weights</span> <span class="pre">biasWeights)=0</span> <span class="pre">-&gt;</span> <span class="pre">IDeconvolutionLayer</span> <span class="pre">*</span></code></p>
<p>Add a deconvolution layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – The input tensor to the layer.</li>
<li><strong>nbOutputMaps</strong> (<em>*</em>) – The number of output feature maps.</li>
<li><strong>kernelSize</strong> (<em>*</em>) – The HW-dimensions of the convolution kernel.</li>
<li><strong>kernelWeights</strong> (<em>*</em>) – The kernel weights for the convolution.</li>
<li><strong>biasWeights</strong> (<em>*</em>) – The optional bias weights for the convolution.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new deconvolution layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_element_wise">
<code class="descname">add_element_wise</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_element_wise" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addElementWise(ITensor</span> <span class="pre">&amp;input1,</span> <span class="pre">ITensor</span> <span class="pre">&amp;input2,</span> <span class="pre">ElementWiseOperation</span> <span class="pre">op)=0</span> <span class="pre">-&gt;</span> <span class="pre">IElementWiseLayer</span> <span class="pre">*</span></code></p>
<p>Add an elementwise layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input1</strong> (<em>*</em>) – The first input tensor to the layer.</li>
<li><strong>input2</strong> (<em>*</em>) – The second input tensor to the layer.</li>
<li><strong>op</strong> (<em>*</em>) – The binary operation that the layer applies.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new elementwise layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_fully_connected">
<code class="descname">add_fully_connected</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_fully_connected" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addFullyConnected(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">int</span> <span class="pre">nbOutputs,</span> <span class="pre">Weights</span> <span class="pre">kernelWeights,</span> <span class="pre">Weights</span> <span class="pre">biasWeights)=0</span> <span class="pre">-&gt;</span> <span class="pre">IFullyConnectedLayer</span> <span class="pre">*</span></code></p>
<p>Add a fully connected layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – The input tensor to the layer.</li>
<li><strong>nbOutputs</strong> (<em>*</em>) – The number of outputs of the layer.</li>
<li><strong>kernelWeights</strong> (<em>*</em>) – The kernel weights for the convolution.</li>
<li><strong>biasWeights</strong> (<em>*</em>) – The optional bias weights for the convolution.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new fully connected layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_gather">
<code class="descname">add_gather</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_gather" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addGather(ITensor</span> <span class="pre">&amp;data,</span> <span class="pre">ITensor</span> <span class="pre">&amp;indices,</span> <span class="pre">int</span> <span class="pre">axis)=0</span> <span class="pre">-&gt;</span> <span class="pre">IGatherLayer</span> <span class="pre">*</span></code></p>
<p>Add a gather layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>*</em>) – The tensor to gather values from.</li>
<li><strong>indices</strong> (<em>*</em>) – The tensor to get indices from to populate the output tensor.</li>
<li><strong>axis</strong> (<em>*</em>) – The non-batch dimension axis in the data tensor to gather on.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new gather layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_input">
<code class="descname">add_input</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_input" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addInput(const</span> <span class="pre">char</span> <span class="pre">*name,</span> <span class="pre">DataType</span> <span class="pre">type,</span> <span class="pre">Dims</span> <span class="pre">dimensions)=0</span> <span class="pre">-&gt;</span> <span class="pre">ITensor</span> <span class="pre">*</span></code></p>
<p>Add an input tensor to the network.</p>
<p>The name of the input tensor is used to find the index into the buffer array for an engine built from the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>*</em>) – The name of the tensor.</li>
<li><strong>type</strong> (<em>*</em>) – The type of the data held in the tensor.</li>
<li><strong>dimensions</strong> (<em>*</em>) – The dimensions of the tensor.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>:param Only DataType::kFLOAT and DataType::kHALF are valid input tensor types. The volume of the dimension, including the maximum batch size, must be less than 2^30 elements.:
:param See also:
:type See also: ITensor</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The new tensor or nullptr if there is an error.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_lrn">
<code class="descname">add_lrn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_lrn" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addLRN(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">int</span> <span class="pre">window,</span> <span class="pre">float</span> <span class="pre">alpha,</span> <span class="pre">float</span> <span class="pre">beta,</span> <span class="pre">float</span> <span class="pre">k)=0</span> <span class="pre">-&gt;</span> <span class="pre">ILRNLayer</span> <span class="pre">*</span></code></p>
<p>Add a LRN layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – The input tensor to the layer.</li>
<li><strong>window</strong> (<em>*</em>) – The size of the window.</li>
<li><strong>alpha</strong> (<em>*</em>) – The alpha value for the LRN computation.</li>
<li><strong>beta</strong> (<em>*</em>) – The beta value for the LRN computation.</li>
<li><strong>k</strong> (<em>*</em>) – The k value for the LRN computation.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new LRN layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_matrix_multiply">
<code class="descname">add_matrix_multiply</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_matrix_multiply" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addMatrixMultiply(ITensor</span> <span class="pre">&amp;input0,</span> <span class="pre">bool</span> <span class="pre">transpose0,</span> <span class="pre">ITensor</span> <span class="pre">&amp;input1,</span> <span class="pre">bool</span> <span class="pre">transpose1)=0</span> <span class="pre">-&gt;</span> <span class="pre">IMatrixMultiplyLayer</span> <span class="pre">*</span></code></p>
<p>Add a MatrixMultiply layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input0</strong> (<em>*</em>) – The first input tensor (commonly A).</li>
<li><strong>transpose0</strong> (<em>*</em>) – If true, op(input0)=transpose(input0), else op(input0)=input0.</li>
<li><strong>input1</strong> (<em>*</em>) – The second input tensor (commonly B).</li>
<li><strong>transpose1</strong> (<em>*</em>) – If true, op(input1)=transpose(input1), else op(input1)=input1.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new matrix multiply layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_padding">
<code class="descname">add_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addPadding(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">DimsHW</span> <span class="pre">prePadding,</span> <span class="pre">DimsHW</span> <span class="pre">postPadding)=0</span> <span class="pre">-&gt;</span> <span class="pre">IPaddingLayer</span> <span class="pre">*</span></code></p>
<p>Add a padding layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – The input tensor to the layer.</li>
<li><strong>prePadding</strong> (<em>*</em>) – The padding to apply to the start of the tensor.</li>
<li><strong>postPadding</strong> (<em>*</em>) – The padding to apply to the end of the tensor.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the new padding layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_plugin">
<code class="descname">add_plugin</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_plugin" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addPlugin(ITensor</span> <span class="pre">*const</span> <span class="pre">*inputs,</span> <span class="pre">int</span> <span class="pre">nbInputs,</span> <span class="pre">IPlugin</span> <span class="pre">&amp;plugin)=0</span> <span class="pre">-&gt;</span> <span class="pre">IPluginLayer</span> <span class="pre">*</span></code></p>
<p>Add a plugin layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> (<em>*</em>) – The input tensors to the layer.</li>
<li><strong>nbInputs</strong> (<em>*</em>) – The number of input tensors.</li>
<li><strong>plugin</strong> (<em>*</em>) – The layer plugin.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the new plugin layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_plugin_ext">
<code class="descname">add_plugin_ext</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_plugin_ext" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addPluginExt(ITensor</span> <span class="pre">*const</span> <span class="pre">*inputs,</span> <span class="pre">int</span> <span class="pre">nbInputs,</span> <span class="pre">IPluginExt</span> <span class="pre">&amp;plugin)=0</span> <span class="pre">-&gt;</span> <span class="pre">IPluginLayer</span> <span class="pre">*</span></code></p>
<p>Add a plugin layer to the network using an IPluginExt interface.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> (<em>*</em>) – The input tensors to the layer.</li>
<li><strong>nbInputs</strong> (<em>*</em>) – The number of input tensors.</li>
<li><strong>plugin</strong> (<em>*</em>) – The layer plugin.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new plugin layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_pooling">
<code class="descname">add_pooling</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_pooling" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addPooling(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">PoolingType</span> <span class="pre">type,</span> <span class="pre">DimsHW</span> <span class="pre">windowSize)=0</span> <span class="pre">-&gt;</span> <span class="pre">IPoolingLayer</span> <span class="pre">*</span></code></p>
<p>Add a pooling layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – The input tensor to the layer.</li>
<li><strong>type</strong> (<em>*</em>) – The type of pooling to apply.</li>
<li><strong>windowSize</strong> (<em>*</em>) – The size of the pooling window.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new pooling layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_ragged_soft_max">
<code class="descname">add_ragged_soft_max</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_ragged_soft_max" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addRaggedSoftMax(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">ITensor</span> <span class="pre">&amp;bounds)=0</span> <span class="pre">-&gt;</span> <span class="pre">IRaggedSoftMaxLayer</span> <span class="pre">*</span></code></p>
<p>Add a RaggedSoftMax layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – The ZxS input tensor.</li>
<li><strong>bounds</strong> (<em>*</em>) – The Zx1 bounds tensor.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new RaggedSoftMax layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_reduce">
<code class="descname">add_reduce</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_reduce" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addReduce(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">ReduceOperation</span> <span class="pre">operation,</span> <span class="pre">uint32_t</span> <span class="pre">reduceAxes,</span> <span class="pre">bool</span> <span class="pre">keepDimensions)=0</span> <span class="pre">-&gt;</span> <span class="pre">IReduceLayer</span> <span class="pre">*</span></code></p>
<p>Add a reduce layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – The input tensor to the layer.</li>
<li><strong>operation</strong> (<em>*</em>) – The reduction operation to perform.</li>
<li><strong>reduceAxes</strong> (<em>*</em>) – The reduction dimensions. Bit 0 of the uint32_t type corresponds to the non-batch dimension 0 boolean and so on. If a bit is set, then the corresponding dimension will be reduced. Let’s say we
have an NCHW tensor as input (three non-batch dimensions). Bit 0 corresponds to the C dimension boolean. Bit 1 corresponds to the H dimension boolean. Bit 2 corresponds to the W dimension boolean.
Note that reduction is not permitted over the batch size dimension.</li>
<li><strong>keepDimensions</strong> (<em>*</em>) – The boolean that specifies whether or not to keep the reduced dimensions in the output of the layer.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new reduce layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_rnn">
<code class="descname">add_rnn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_rnn" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addRNN(ITensor</span> <span class="pre">&amp;inputs,</span> <span class="pre">int</span> <span class="pre">layerCount,</span> <span class="pre">std::size_t</span> <span class="pre">hiddenSize,</span> <span class="pre">int</span> <span class="pre">maxSeqLen,</span> <span class="pre">RNNOperation</span> <span class="pre">op,</span> <span class="pre">RNNInputMode</span> <span class="pre">mode,</span> <span class="pre">RNNDirection</span> <span class="pre">dir,</span> <span class="pre">Weights</span> <span class="pre">weights,</span> <span class="pre">Weights</span> <span class="pre">bias)=0</span> <span class="pre">-&gt;</span> <span class="pre">IRNNLayer</span> <span class="pre">*</span></code></p>
<p>Add an <cite>layerCount</cite> deep RNN layer to the network with a sequence length of <cite>maxSeqLen</cite> and <cite>hiddenSize</cite> internal state per layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>inputs</strong> (<em>*</em>) – The input tensor to the layer.</li>
<li><strong>layerCount</strong> (<em>*</em>) – The number of layers in the RNN.</li>
<li><strong>hiddenSize</strong> (<em>*</em>) – The size of the internal hidden state for each layer.</li>
<li><strong>maxSeqLen</strong> (<em>*</em>) – The maximum length of the time sequence.</li>
<li><strong>op</strong> (<em>*</em>) – The type of RNN to execute.</li>
<li><strong>mode</strong> (<em>*</em>) – The input mode for the RNN.</li>
<li><strong>dir</strong> (<em>*</em>) – The direction to run the RNN.</li>
<li><strong>weights</strong> (<em>*</em>) – The weights for the weight matrix parameters of the RNN.</li>
<li><strong>bias</strong> (<em>*</em>) – The weights for the bias vectors parameters of the RNN.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>:param The input tensors must be of the type DataType::kFLOAT or DataType::kHALF.:
:param See IRNNLayer::setWeights() and IRNNLayer::setBias() for details on the required input format for <cite>weights</cite> and <cite>bias</cite>.:
:param The layout for the <cite>input</cite> tensor should be <cite>{1, S_max, N, E}</cite>, where:
:param *   <cite>S_max</cite> is the maximum allowed sequence length (number of RNN iterations):
:param *   <cite>N</cite> is the batch size:
:param *   <cite>E</cite> specifies the embedding length (unless kSKIP is set, in which case it should match getHiddenSize()).:
:param The first output tensor is the output of the final RNN layer across all timesteps, with dimensions <cite>{S_max, N, H}</cite>:
:param *   <cite>S_max</cite> is the maximum allowed sequence length (number of RNN iterations):
:param *   <cite>N</cite> is the batch size:
:param *   <cite>H</cite> is an output hidden state (equal to getHiddenSize() or 2x getHiddenSize()):
:param The second tensor is the final hidden state of the RNN across all layers, and if the RNN is an LSTM (i.e. getOperation() is kLSTM), then the third tensor is the final cell state of the RNN across all:
:param layers. Both the second and third output tensors have dimensions <cite>{L, N, H}</cite>:
:param *   <cite>L</cite> is equal to getLayerCount() if getDirection is kUNIDIRECTION, and 2*getLayerCount() if getDirection is kBIDIRECTION. In the bi-directional case, layer <cite>l</cite>’s final forward hidden state is: stored in <cite>L = 2*l</cite>, and final backward hidden state is stored in <cite>L = 2*l + 1</cite>.
:param *   <cite>N</cite> is the batch size:
:param *   <cite>H</cite> is getHiddenSize().:
:param Note that in bidirectional RNNs, the full “hidden state” for a layer <cite>l</cite> is the concatenation of its forward hidden state and its backward hidden state, and its size is 2*H.:
:param Deprecated:
:param IRNNLayer is superseded by IRNNv2Layer. Use addRNNv2() instead.:</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The new RNN layer, or null if it could not be created.</em></li>
<li><strong>See also</strong> (<em>IRNNLayer</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_rnnv2">
<code class="descname">add_rnnv2</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_rnnv2" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addRNNv2(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">int32_t</span> <span class="pre">layerCount,</span> <span class="pre">int32_t</span> <span class="pre">hiddenSize,</span> <span class="pre">int32_t</span> <span class="pre">maxSeqLen,</span> <span class="pre">RNNOperation</span> <span class="pre">op)=0</span> <span class="pre">-&gt;</span> <span class="pre">IRNNv2Layer</span> <span class="pre">*</span></code></p>
<p>Add an <cite>layerCount</cite> deep RNN layer to the network with <cite>hiddenSize</cite> internal states that can take a batch with fixed or variable sequence lengths.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<em>*</em>) – The input tensor to the layer (see below).</li>
<li><strong>layerCount</strong> (<em>*</em>) – The number of layers in the RNN.</li>
<li><strong>hiddenSize</strong> (<em>*</em>) – Size of the internal hidden state for each layer.</li>
<li><strong>maxSeqLen</strong> (<em>*</em>) – Maximum sequence length for the input.</li>
<li><strong>op</strong> (<em>*</em>) – The type of RNN to execute.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>:param By default, the layer is configured with RNNDirection::kUNIDIRECTION and RNNInputMode::kLINEAR. To change these settings, use IRNNv2Layer::setDirection() and IRNNv2Layer::setInputMode().:
:param Weights and biases for the added layer should be set using IRNNv2Layer::setWeightsForGate() and IRNNv2Layer::setBiasForGate() prior to building an engine using this network.:
:param The input tensors must be of the type DataType::kFLOAT or DataType::kHALF. The layout of the weights is row major and must be the same datatype as the input tensor. <cite>weights</cite> contain 8 matrices and:
:param <cite>bias</cite> contains 8 vectors.:
:param See IRNNv2Layer::setWeightsForGate() and IRNNv2Layer::setBiasForGate() for details on the required input format for <cite>weights</cite> and <cite>bias</cite>.:
:param The <cite>input</cite> ITensor should contain zero or more index dimensions <cite>{N1, …, Np}</cite>, followed by two dimensions, defined as follows:
:param *   <cite>S_max</cite> is the maximum allowed sequence length (number of RNN iterations):
:param *   <cite>E</cite> specifies the embedding length (unless kSKIP is set, in which case it should match getHiddenSize()).:
:param By default, all sequences in the input are assumed to be size <cite>maxSeqLen</cite>. To provide explicit sequence lengths for each input sequence in the batch, use IRNNv2Layer::setSequenceLengths().:
:param The RNN layer outputs up to three tensors.:
:param The first output tensor is the output of the final RNN layer across all timesteps, with dimensions <cite>{N1, …, Np, S_max, H}</cite>:
:param *   <cite>N1..Np</cite> are the index dimensions specified by the input tensor:
:param *   <cite>S_max</cite> is the maximum allowed sequence length (number of RNN iterations):
:param *   <cite>H</cite> is an output hidden state (equal to getHiddenSize() or 2x getHiddenSize()):
:param The second tensor is the final hidden state of the RNN across all layers, and if the RNN is an LSTM (i.e. getOperation() is kLSTM), then the third tensor is the final cell state of the RNN across all:
:param layers. Both the second and third output tensors have dimensions <cite>{N1, …, Np, L, H}</cite>:
:param *   <cite>N1..Np</cite> are the index dimensions specified by the input tensor:
:param *   <cite>L</cite> is the number of layers in the RNN, equal to getLayerCount():
:param *   <cite>H</cite> is the hidden state for each layer, equal to getHiddenSize() if getDirection is kUNIDIRECTION, and 2x getHiddenSize() otherwise.:</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The new RNN layer, or null if it could not be created.</em></li>
<li><strong>See also</strong> (<em>IRNNv2Layer</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_scale">
<code class="descname">add_scale</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_scale" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addScale(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">ScaleMode</span> <span class="pre">mode,</span> <span class="pre">Weights</span> <span class="pre">shift,</span> <span class="pre">Weights</span> <span class="pre">scale,</span> <span class="pre">Weights</span> <span class="pre">power)=0</span> <span class="pre">-&gt;</span> <span class="pre">IScaleLayer</span> <span class="pre">*</span></code></p>
<p>Add a Scale layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – The input tensor to The layer. This tensor is required to have a minimum of 3 dimensions.</li>
<li><strong>mode</strong> (<em>*</em>) – The scaling mode.</li>
<li><strong>shift</strong> (<em>*</em>) – The shift value.</li>
<li><strong>scale</strong> (<em>*</em>) – The scale value.</li>
<li><strong>power</strong> (<em>*</em>) – The power value.</li>
<li><strong>the weights are available</strong><strong>, </strong><strong>then the size of weights are dependent on the on the ScaleMode. For kUNIFORM</strong><strong>, </strong><strong>the number of weights is equal to 1. For kCHANNEL</strong><strong>, </strong><strong>the number of weights is equal to the</strong> (<em>If</em>) – </li>
<li><strong>dimension. For kELEMENTWISE</strong><strong>, </strong><strong>the number of weights is equal to the volume of the input.</strong> (<em>channel</em>) – </li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new Scale layer, or null if it could not be created.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_shuffle">
<code class="descname">add_shuffle</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_shuffle" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addShuffle(ITensor</span> <span class="pre">&amp;input)=0</span> <span class="pre">-&gt;</span> <span class="pre">IShuffleLayer</span> <span class="pre">*</span></code></p>
<p>Add a shuffle layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input</strong> (<em>*</em>) – The input tensor to the layer.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">The new shuffle layer, or null if it could not be created.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_softmax">
<code class="descname">add_softmax</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addSoftMax(ITensor</span> <span class="pre">&amp;input)=0</span> <span class="pre">-&gt;</span> <span class="pre">ISoftMaxLayer</span> <span class="pre">*</span></code></p>
<p>Add a SoftMax layer to the network.</p>
<p>See also: ISoftMaxLayer</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The new SoftMax layer, or null if it could not be created.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_top_k">
<code class="descname">add_top_k</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_top_k" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addTopK(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">TopKOperation</span> <span class="pre">op,</span> <span class="pre">int</span> <span class="pre">k,</span> <span class="pre">uint32_t</span> <span class="pre">reduceAxes)=0</span> <span class="pre">-&gt;</span> <span class="pre">ITopKLayer</span> <span class="pre">*</span></code></p>
<p>Add a TopK layer to the network.</p>
<p>The TopK layer has two outputs of the same dimensions. The first contains data values, the second contains index positions for the values. Output values are sorted, largest first for operation kMAX
and smallest first for operation kMIN.</p>
<p>Currently only values of K up to 1024 are supported.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<em>*</em>) – The input tensor to the layer.</li>
<li><strong>op</strong> (<em>*</em>) – Operation to perform.</li>
<li><strong>k</strong> (<em>*</em>) – Number of elements to keep.</li>
<li><strong>reduceAxes</strong> (<em>*</em>) – The reduction dimensions. Bit 0 of the uint32_t type corresponds to the non-batch dimension 0 boolean and so on. If a bit is set, then the corresponding dimension will be reduced. Let’s say we
have an NCHW tensor as input (three non-batch dimensions). Bit 0 corresponds to the C dimension boolean. Bit 1 corresponds to the H dimension boolean. Bit 2 corresponds to the W dimension boolean.
Note that TopK reduction is currently only permitted over one dimension.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_unary">
<code class="descname">add_unary</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_unary" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">addUnary(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">UnaryOperation</span> <span class="pre">operation)=0</span> <span class="pre">-&gt;</span> <span class="pre">IUnaryLayer</span> <span class="pre">*</span></code></p>
<p>Add a unary layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – The input tensor to the layer.</li>
<li><strong>operation</strong> (<em>*</em>) – The operation to apply.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The new unary layer, or null if it could not be created</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.destroy">
<code class="descname">destroy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.destroy" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">destroy()=0</span></code></p>
<p>Destroy this INetworkDefinition object.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_convolution_output_dimensions_formula">
<code class="descname">get_convolution_output_dimensions_formula</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_convolution_output_dimensions_formula" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getConvolutionOutputDimensionsFormula()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">IOutputDimensionsFormula</span> <span class="pre">&amp;</span></code></p>
<p>Get the convolution output dimensions formula.</p>
<p>Deprecated
This method does not currently work reliably and will be removed in a future release.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The formula from computing the convolution output dimensions.</em></li>
<li><strong>See also</strong> (<em>IOutputDimensionsFormula setConvolutionOutputDimensionsFormula()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_deconvolution_output_dimensions_formula">
<code class="descname">get_deconvolution_output_dimensions_formula</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_deconvolution_output_dimensions_formula" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getDeconvolutionOutputDimensionsFormula()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">IOutputDimensionsFormula</span> <span class="pre">&amp;</span></code></p>
<p>Get the deconvolution output dimensions formula.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The formula from computing the deconvolution output dimensions.</em></li>
<li><em>Deprecated</em></li>
<li><em>This method does not currently work reliably and will be removed in a future release.</em></li>
<li><strong>See also</strong> (<em>IOutputDimensionsFormula setDeconvolutionOutputDimensionsFormula()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_input">
<code class="descname">get_input</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_input" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getInput(int</span> <span class="pre">index)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ITensor</span> <span class="pre">*</span></code></p>
<p>Get the input tensor specified by the given index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<em>*</em>) – The index of the input tensor.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The input tensor, or null if the index is out of range.</em></li>
<li><strong>See also</strong> (<em>getNbInputs()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_layer">
<code class="descname">get_layer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_layer" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getLayer(int</span> <span class="pre">index)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ILayer</span> <span class="pre">*</span></code></p>
<p>Get the layer specified by the given index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<em>*</em>) – The index of the layer.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The layer, or null if the index is out of range.</em></li>
<li><strong>See also</strong> (<em>getNbLayers()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_nb_inputs">
<code class="descname">get_nb_inputs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_nb_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getNbInputs()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the number of inputs in the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The number of inputs in the network.</em></li>
<li><strong>See also</strong> (<em>getInput()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_nb_layers">
<code class="descname">get_nb_layers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_nb_layers" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getNbLayers()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the number of layers in the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The number of layers in the network.</em></li>
<li><strong>See also</strong> (<em>getLayer()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_nb_outputs">
<code class="descname">get_nb_outputs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_nb_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getNbOutputs()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the number of outputs in the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The number of outputs in the network.</em></li>
<li><strong>See also</strong> (<em>getOutput()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_output">
<code class="descname">get_output</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_output" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getOutput(int</span> <span class="pre">index)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ITensor</span> <span class="pre">*</span></code></p>
<p>Get the output tensor specified by the given index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<em>*</em>) – The index of the output tensor.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The output tensor, or null if the index is out of range.</em></li>
<li><strong>See also</strong> (<em>getNbOutputs()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_pooling_output_dimensions_formula">
<code class="descname">get_pooling_output_dimensions_formula</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_pooling_output_dimensions_formula" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getPoolingOutputDimensionsFormula()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">IOutputDimensionsFormula</span> <span class="pre">&amp;</span></code></p>
<p>Get the pooling output dimensions formula.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The formula from computing the pooling output dimensions.</em></li>
<li><strong>See also</strong> (<em>IOutputDimensionsFormula setPoolingOutputDimensionsFormula()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.mark_output">
<code class="descname">mark_output</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.mark_output" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">markOutput(ITensor</span> <span class="pre">&amp;tensor)=0</span></code></p>
<p>Mark a tensor as a network output.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>tensor</strong> (<em>*</em>) – The tensor to mark as an output tensor.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.set_convolution_output_dimensions_formula">
<code class="descname">set_convolution_output_dimensions_formula</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.set_convolution_output_dimensions_formula" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setConvolutionOutputDimensionsFormula(IOutputDimensionsFormula</span> <span class="pre">*formula)=0</span></code></p>
<p>Set the convolution output dimensions formula.</p>
<p>Deprecated
This method does not currently work reliably and will be removed in a future release.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>formula</strong> (<em>*</em>) – The formula from computing the convolution output dimensions. If null is passed, the default formula is used.</li>
<li><strong>default formula in each dimension is</strong><strong> (</strong><strong>inputDim + padding * 2 - kernelSize</strong><strong>) </strong><strong>/ stride + 1.</strong> (<em>The</em>) – </li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.set_deconvolution_output_dimensions_formula">
<code class="descname">set_deconvolution_output_dimensions_formula</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.set_deconvolution_output_dimensions_formula" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setDeconvolutionOutputDimensionsFormula(IOutputDimensionsFormula</span> <span class="pre">*formula)=0</span></code></p>
<p>Set the deconvolution output dimensions formula.</p>
<p>Deprecated
This method does not currently work reliably and will be removed in a future release.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>formula</strong> (<em>*</em>) – The formula from computing the deconvolution output dimensions. If null is passed, the default formula is used.</li>
<li><strong>default formula in each dimension is</strong><strong> (</strong><strong>inputDim - 1</strong><strong>) </strong><strong>* stride + kernelSize - 2 * padding.</strong> (<em>The</em>) – </li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.set_pooling_output_dimensions_formula">
<code class="descname">set_pooling_output_dimensions_formula</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.set_pooling_output_dimensions_formula" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setPoolingOutputDimensionsFormula(IOutputDimensionsFormula</span> <span class="pre">*formula)=0</span></code></p>
<p>Set the pooling output dimensions formula.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>formula</strong> (<em>*</em>) – The formula from computing the pooling output dimensions. If null is passed, the default formula is used.</li>
<li><strong>default formula in each dimension is</strong><strong> (</strong><strong>inputDim + padding * 2 - kernelSize</strong><strong>) </strong><strong>/ stride + 1.</strong> (<em>The</em>) – </li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="layertype">
<h3>LayerType<a class="headerlink" href="#layertype" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.LayerType">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">LayerType</code><a class="headerlink" href="#tensorrt.infer.LayerType" title="Permalink to this definition">¶</a></dt>
<dd><p>Available layer types</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="tensor">
<h3>Tensor<a class="headerlink" href="#tensor" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Tensor">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Tensor</code><a class="headerlink" href="#tensorrt.infer.Tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>A tensor in a network definition.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Tensor.get_broadcast_across_batch">
<code class="descname">get_broadcast_across_batch</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.get_broadcast_across_batch" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getBroadcastAcrossBatch()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Check if tensor is broadcast across the batch.</p>
<p>When a tensor is broadcast across a batch, it has the same value for every member in the batch. Memory is only allocated once for the single member.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>True if tensor is broadcast across the batch, false otherwise.</em></li>
<li><strong>See also</strong> (<em>setBroadcastAcrossBatch()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.get_dimensions">
<code class="descname">get_dimensions</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.get_dimensions" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getDimensions()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Dims</span></code></p>
<p>Get the dimensions of a tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The dimensions of the layer.</em></li>
<li><strong>See also</strong> (<em>setDimensions()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.get_location">
<code class="descname">get_location</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.get_location" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getLocation()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">TensorLocation</span></code></p>
<p>Get the storage location of a tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The location of tensor data.</em></li>
<li><strong>See also</strong> (<em>setLocation()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.get_name">
<code class="descname">get_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.get_name" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getName()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">const</span> <span class="pre">char</span> <span class="pre">*</span></code></p>
<p>Get the tensor name.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The name, as a pointer to a NULL-terminated character sequence.</em></li>
<li><strong>See also</strong> (<em>setName()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.get_type">
<code class="descname">get_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.get_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getType()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DataType</span></code></p>
<p>Get the data type of a tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The data type of the tensor.</em></li>
<li><strong>See also</strong> (<em>setType()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.is_network_input">
<code class="descname">is_network_input</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.is_network_input" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">isNetworkInput()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Whether the tensor is a network input.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.is_network_output">
<code class="descname">is_network_output</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.is_network_output" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">isNetworkOutput()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Whether the tensor is a network output.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.set_broadcast_across_batch">
<code class="descname">set_broadcast_across_batch</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.set_broadcast_across_batch" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setBroadcastAcrossBatch(bool</span> <span class="pre">broadcastAcrossBatch)=0</span></code></p>
<p>Set whether to enable broadcast of tensor across the batch.</p>
<p>When a tensor is broadcast across a batch, it has the same value for every member in the batch. Memory is only allocated once for the single member.</p>
<p>This method is only valid for network input tensors, since the flags of layer output tensors are inferred based on layer inputs and parameters. If this state is modified for a tensor in the network,
the states of all dependent tensors will be recomputed.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>broadcastAcrossBatch</strong> (<em>*</em>) – Whether to enable broadcast of tensor across the batch.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.set_dimensions">
<code class="descname">set_dimensions</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.set_dimensions" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setDimensions(Dims</span> <span class="pre">dimensions)=0</span></code></p>
<p>Set the dimensions of a tensor.</p>
<p>For a network input the name is assigned by the application. For a network output it is computed based on the layer parameters and the inputs to the layer. If a tensor size or a parameter is modified
in the network, the dimensions of all dependent tensors will be recomputed.</p>
<p>This call is only legal for network input tensors, since the dimensions of layer output tensors are inferred based on layer inputs and parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dimensions</strong> (<em>*</em>) – The dimensions of the tensor.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.set_location">
<code class="descname">set_location</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.set_location" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setLocation(TensorLocation</span> <span class="pre">location)=0</span></code></p>
<p>Set the storage location of a tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>location</strong> (<em>*</em>) – the location of tensor data</li>
<li><strong>input tensors for storing sequence lengths for RNNv2 are supported. Using host storage for layers that do not support it will generate errors at build time.</strong> (<em>Only</em>) – </li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.set_name">
<code class="descname">set_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.set_name" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setName(const</span> <span class="pre">char</span> <span class="pre">*name)=0</span></code></p>
<p>Set the tensor name.</p>
<p>For a network input, the name is assigned by the application. For tensors which are layer outputs, a default name is assigned consisting of the layer name followed by the index of the output in
brackets.</p>
<p>This method copies the name string.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>*</em>) – The name.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.set_type">
<code class="descname">set_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.set_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setType(DataType</span> <span class="pre">type)=0</span></code></p>
<p>Set the data type of a tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>type</strong> (<em>*</em>) – The data type of the tensor.</li>
<li><strong>type is unchanged if the type is invalid for the given tensor.</strong> (<em>The</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>:param If the tensor is a network input or output, then the tensor type cannot be DataType::kINT8.:
:param See also:
:type See also: getType()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="layer">
<h3>Layer<a class="headerlink" href="#layer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Layer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Layer</code><a class="headerlink" href="#tensorrt.infer.Layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for all layer classes in a network definition.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Layer.get_input">
<code class="descname">get_input</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Layer.get_input" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getInput(int</span> <span class="pre">index)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ITensor</span> <span class="pre">*</span></code></p>
<p>Get the layer input corresponding to the given index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<em>*</em>) – The index of the input tensor.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">The input tensor, or nullptr if the index is out of range.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Layer.get_name">
<code class="descname">get_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Layer.get_name" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getName()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">const</span> <span class="pre">char</span> <span class="pre">*</span></code></p>
<p>Return the name of a layer.</p>
<p>See also: setName()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Layer.get_nb_inputs">
<code class="descname">get_nb_inputs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Layer.get_nb_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getNbInputs()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the number of inputs of a layer.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Layer.get_nb_outputs">
<code class="descname">get_nb_outputs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Layer.get_nb_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getNbOutputs()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the number of outputs of a layer.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Layer.get_output">
<code class="descname">get_output</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Layer.get_output" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getOutput(int</span> <span class="pre">index)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ITensor</span> <span class="pre">*</span></code></p>
<p>Get the layer output corresponding to the given index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The indexed output tensor, or nullptr if the index is out of range.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Layer.get_type">
<code class="descname">get_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Layer.get_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getType()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">LayerType</span></code></p>
<p>Return the type of a layer.</p>
<p>See also: LayerType</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Layer.set_name">
<code class="descname">set_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Layer.set_name" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setName(const</span> <span class="pre">char</span> <span class="pre">*name)=0</span></code></p>
<p>Set the name of a layer.</p>
<p>This method copies the name string.</p>
<p>See also: getName()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="convolutionlayer">
<h3>ConvolutionLayer<a class="headerlink" href="#convolutionlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ConvolutionLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ConvolutionLayer</code><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>A convolution layer in a network definition.</p>
<p>This layer performs a correlation operation between 3-dimensional filter with a 4-dimensional tensor to produce another 4-dimensional tensor.</p>
<p>The HW output size of the convolution is set according to the <cite>INetworkCustomDimensions</cite> set in INetworkDefinition::setCustomConvolutionDimensions().</p>
<p>An optional bias argument is supported, which adds a per-channel constant to each value in the output.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_bias_weights">
<code class="descname">get_bias_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_bias_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getBiasWeights()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>Get the bias weights for the convolution.</p>
<p>See also: setBiasWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_dilation">
<code class="descname">get_dilation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_dilation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getDilation()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>Get the dilation for a convolution.</p>
<p>See also: setDilation()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_kernel_size">
<code class="descname">get_kernel_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_kernel_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getKernelSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>Get the HW kernel size of the convolution.</p>
<p>See also: setKernelSize()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_kernel_weights">
<code class="descname">get_kernel_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_kernel_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getKernelWeights()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>Get the kernel weights for the convolution.</p>
<p>See also: setKernelWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_nb_groups">
<code class="descname">get_nb_groups</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_nb_groups" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getNbGroups()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Set the number of groups for a convolution.</p>
<p>See also: setNbGroups()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_nb_output_maps">
<code class="descname">get_nb_output_maps</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_nb_output_maps" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getNbOutputMaps()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the number of output maps for the convolution.</p>
<p>See also: setNbOutputMaps()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_padding">
<code class="descname">get_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getPadding()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>Get the padding of the convolution.</p>
<p>See also: setPadding()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_stride">
<code class="descname">get_stride</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_stride" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getStride()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>Get the stride of the convolution.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_bias_weights">
<code class="descname">set_bias_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_bias_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setBiasWeights(Weights</span> <span class="pre">weights)=0</span></code></p>
<p>Set the bias weights for the convolution.</p>
<p>Bias is optional. To omit bias, set the count value of the weights structure to zero.</p>
<p>The bias is applied per-channel, so the number of weights (if non-zero) must be equal to the number of output feature maps.</p>
<p>See also: getBiasWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_dilation">
<code class="descname">set_dilation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_dilation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setDilation(DimsHW</span> <span class="pre">dims)=0</span></code></p>
<p>Set the dilation for a convolution.</p>
<p>Default: (1,1)</p>
<p>See also: getDilation()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_kernel_size">
<code class="descname">set_kernel_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_kernel_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setKernelSize(DimsHW</span> <span class="pre">kernelSize)=0</span></code></p>
<p>Set the HW kernel size of the convolution.</p>
<p>See also: getKernelSize()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_kernel_weights">
<code class="descname">set_kernel_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_kernel_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setKernelWeights(Weights</span> <span class="pre">weights)=0</span></code></p>
<p>Set the kernel weights for the convolution.</p>
<p>The weights are specified as a contiguous array in <cite>GKCRS</cite> order, where <cite>G</cite> is the number of groups, <cite>K</cite> the number of output feature maps, <cite>C</cite> the number of input channels, and <cite>R</cite> and <cite>S</cite> are the
height and width of the filter.</p>
<p>See also: getKernelWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_nb_groups">
<code class="descname">set_nb_groups</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_nb_groups" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setNbGroups(int</span> <span class="pre">nbGroups)=0</span></code></p>
<p>Set the number of groups for a convolution.</p>
<p>The input tensor channels are divided into <cite>nbGroups</cite> groups, and a convolution is executed for each group, using a filter per group. The results of the group convolutions are concatenated to form the
output.</p>
<p>note: When using groups in int8 mode, the size of the groups (i.e. the channel count divided by the group count) must be a multiple of 4 for both input and output.</p>
<p>Default: 1</p>
<p>See also: getNbGroups()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_nb_output_maps">
<code class="descname">set_nb_output_maps</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_nb_output_maps" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setNbOutputMaps(int</span> <span class="pre">nbOutputMaps)=0</span></code></p>
<p>Set the number of output maps for the convolution.</p>
<p>See also: getNbOutputMaps()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_padding">
<code class="descname">set_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setPadding(DimsHW</span> <span class="pre">padding)=0</span></code></p>
<p>Set the padding of the convolution.</p>
<p>The input will be zero-padded by this number of elements in the height and width directions. Padding is symmetric.</p>
<p>Default: (0,0)</p>
<p>See also: getPadding()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_stride">
<code class="descname">set_stride</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_stride" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setStride(DimsHW</span> <span class="pre">stride)=0</span></code></p>
<p>Get the stride of the convolution.</p>
<p>Default: (1,1)</p>
<p>See also: setStride()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="fullyconnectedlayer">
<h3>FullyConnectedLayer<a class="headerlink" href="#fullyconnectedlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.FullyConnectedLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">FullyConnectedLayer</code><a class="headerlink" href="#tensorrt.infer.FullyConnectedLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>A fully connected layer in a network definition. This layer expects an input tensor of three or more non-batch dimensions. The input is automatically reshaped into an <cite>MxV</cite> tensor <cite>X</cite>, where <cite>V</cite> is a
product of the last three dimensions and <cite>M</cite> is a product of the remaining dimensions (where the product over 0 dimensions is defined as 1). For example:</p>
<ul class="simple">
<li>If the input tensor has shape <cite>{C, H, W}</cite>, then the tensor is reshaped into <cite>{1, C*H*W}</cite>.</li>
<li>If the input tensor has shape <cite>{P, C, H, W}</cite>, then the tensor is reshaped into <cite>{P, C*H*W}</cite>.</li>
</ul>
<p>The layer then performs the following operation:</p>
<p>Where <cite>X</cite> is the <cite>MxV</cite> tensor defined above, <cite>W</cite> is the <cite>KxV</cite> weight tensor of the layer, and <cite>bias</cite> is a row vector size <cite>K</cite> that is broadcasted to <cite>MxK</cite>. <cite>K</cite> is the number of output channels, and
configurable via setNbOutputChannels(). If <cite>bias</cite> is not specified, it is implicitly <cite>0</cite>.</p>
<p>The <cite>MxK</cite> result <cite>Y</cite> is then reshaped such that the last three dimensions are <cite>{K, 1, 1}</cite> and the remaining dimensions match the dimensions of the input tensor. For example:</p>
<ul class="simple">
<li>If the input tensor has shape <cite>{C, H, W}</cite>, then the output tensor will have shape <cite>{K, 1, 1}</cite>.</li>
<li>If the input tensor has shape <cite>{P, C, H, W}</cite>, then the output tensor will have shape <cite>{P, K, 1, 1}</cite>.</li>
</ul>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.FullyConnectedLayer.get_bias_weights">
<code class="descname">get_bias_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.FullyConnectedLayer.get_bias_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getBiasWeights()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>Get the bias weights.</p>
<p>See also: setBiasWeightsWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.FullyConnectedLayer.get_kernel_weights">
<code class="descname">get_kernel_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.FullyConnectedLayer.get_kernel_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getKernelWeights()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>Get the kernel weights.</p>
<p>See also: setKernelWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.FullyConnectedLayer.get_nb_output_channels">
<code class="descname">get_nb_output_channels</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.FullyConnectedLayer.get_nb_output_channels" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getNbOutputChannels()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the number of output channels <cite>K</cite> from the fully connected layer.</p>
<p>See also: setNbOutputChannels()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.FullyConnectedLayer.set_bias_weights">
<code class="descname">set_bias_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.FullyConnectedLayer.set_bias_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setBiasWeights(Weights</span> <span class="pre">weights)=0</span></code></p>
<p>Set the bias weights.</p>
<p>Bias is optional. To omit bias, set the count value in the weights structure to zero.</p>
<p>See also: getBiasWeightsWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.FullyConnectedLayer.set_kernel_weights">
<code class="descname">set_kernel_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.FullyConnectedLayer.set_kernel_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setKernelWeights(Weights</span> <span class="pre">weights)=0</span></code></p>
<p>Set the kernel weights, given as a <cite>KxC</cite> matrix in row-major order.</p>
<p>See also: getKernelWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.FullyConnectedLayer.set_nb_output_channels">
<code class="descname">set_nb_output_channels</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.FullyConnectedLayer.set_nb_output_channels" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setNbOutputChannels(int</span> <span class="pre">nbOutputs)=0</span></code></p>
<p>Set the number of output channels <cite>K</cite> from the fully connected layer.</p>
<p>See also: getNbOutputChannels()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="activationlayer">
<h3>ActivationLayer<a class="headerlink" href="#activationlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ActivationLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ActivationLayer</code><a class="headerlink" href="#tensorrt.infer.ActivationLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>An Activation layer in a network definition.</p>
<p>This layer applies a per-element activation function to its input.</p>
<p>The output has the same shape as the input.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.ActivationLayer.get_activation_type">
<code class="descname">get_activation_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ActivationLayer.get_activation_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getActivationType()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ActivationType</span></code></p>
<p>Get the type of activation to be performed.</p>
<p>See also: setActivationType(), ActivationType</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ActivationLayer.set_activation_type">
<code class="descname">set_activation_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ActivationLayer.set_activation_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setActivationType(ActivationType</span> <span class="pre">type)=0</span></code></p>
<p>Set the type of activation to be performed.</p>
<p>See also: getActivationType(), ActivationType</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="activationtype">
<h3>ActivationType<a class="headerlink" href="#activationtype" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ActivationType">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ActivationType</code><a class="headerlink" href="#tensorrt.infer.ActivationType" title="Permalink to this definition">¶</a></dt>
<dd><p>Type of activation function</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="poolinglayer">
<h3>PoolingLayer<a class="headerlink" href="#poolinglayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.PoolingLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">PoolingLayer</code><a class="headerlink" href="#tensorrt.infer.PoolingLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>A Pooling layer in a network definition.</p>
<p>The layer applies a reduction operation within a window over the input.</p>
<p>The output size is determined from the input size using the formula set by INetworkDefinition::setCustomPoolingDimensions().</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.get_average_count_excludes_padding">
<code class="descname">get_average_count_excludes_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.get_average_count_excludes_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getAverageCountExcludesPadding()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Get whether exclusive pooling uses as a denominator the overlap area betwen the window and the unpadded input.</p>
<p>See also: setAverageCountExcludesPadding()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.get_blend_factor">
<code class="descname">get_blend_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.get_blend_factor" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getBlendFactor()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p>
<p>Get the blending factor for the max_average_blend mode: max_average_blendPool = (1-blendFactor)*maxPool + blendFactor*avgPool blendFactor is a user value in [0,1] with the default value of 0.0 In
modes other than kMAX_AVERAGE_BLEND, blendFactor is ignored.</p>
<p>See also: setBlendFactor()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.get_padding">
<code class="descname">get_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.get_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getPadding()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>Get the padding for pooling.</p>
<p>Default: 0</p>
<p>See also: getStride()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.get_pooling_type">
<code class="descname">get_pooling_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.get_pooling_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getPoolingType()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">PoolingType</span></code></p>
<p>Get the type of activation to be performed.</p>
<p>See also: setPoolingType(), PoolingType</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.get_stride">
<code class="descname">get_stride</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.get_stride" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getStride()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>Get the stride for pooling.</p>
<p>See also: setStride()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.get_window_size">
<code class="descname">get_window_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.get_window_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getWindowSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>Get the window size for pooling.</p>
<p>See also: setWindowSize()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.set_average_count_excludes_padding">
<code class="descname">set_average_count_excludes_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.set_average_count_excludes_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setAverageCountExcludesPadding(bool</span> <span class="pre">exclusive)=0</span></code></p>
<p>Set whether average pooling uses as a denominator the overlap area between the window and the unpadded input. If this is not set, the denominator is the overlap between the pooling window and the
padded input.</p>
<p>Default: true</p>
<p>See also: getAverageCountExcludesPadding()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.set_blend_factor">
<code class="descname">set_blend_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.set_blend_factor" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setBlendFactor(float</span> <span class="pre">blendFactor)=0</span></code></p>
<p>Set the blending factor for the max_average_blend mode: max_average_blendPool = (1-blendFactor)*maxPool + blendFactor*avgPool blendFactor is a user value in [0,1] with the default value of 0.0 This
value only applies for the kMAX_AVERAGE_BLEND mode.</p>
<p>See also: getBlendFactor()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.set_padding">
<code class="descname">set_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.set_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setPadding(DimsHW</span> <span class="pre">padding)=0</span></code></p>
<p>Set the padding for pooling.</p>
<p>Default: 0</p>
<p>See also: getStride()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.set_pooling_type">
<code class="descname">set_pooling_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.set_pooling_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setPoolingType(PoolingType</span> <span class="pre">type)=0</span></code></p>
<p>Set the type of activation to be performed.</p>
<p>See also: getPoolingType(), PoolingType</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.set_stride">
<code class="descname">set_stride</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.set_stride" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setStride(DimsHW</span> <span class="pre">stride)=0</span></code></p>
<p>Set the stride for pooling.</p>
<p>Default: 1</p>
<p>See also: getStride()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.set_window_size">
<code class="descname">set_window_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.set_window_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setWindowSize(DimsHW</span> <span class="pre">windowSize)=0</span></code></p>
<p>Set the window size for pooling.</p>
<p>See also: getWindowSize()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="poolingtype">
<h3>PoolingType<a class="headerlink" href="#poolingtype" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.PoolingType">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">PoolingType</code><a class="headerlink" href="#tensorrt.infer.PoolingType" title="Permalink to this definition">¶</a></dt>
<dd><p>Type of pooling layer</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="lrnlayer">
<h3>LRNLayer<a class="headerlink" href="#lrnlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.LRNLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">LRNLayer</code><a class="headerlink" href="#tensorrt.infer.LRNLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>A LRN layer in a network definition.</p>
<p>The output size is the same as the input size.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.LRNLayer.get_alpha">
<code class="descname">get_alpha</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.get_alpha" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getAlpha()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p>
<p>Get the LRN alpha value.</p>
<p>See also: setAlpha()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.LRNLayer.get_beta">
<code class="descname">get_beta</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.get_beta" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getBeta()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p>
<p>Get the LRN beta value.</p>
<p>See also: setBeta()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.LRNLayer.get_k">
<code class="descname">get_k</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.get_k" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getK()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p>
<p>Get the LRN K value.</p>
<p>See also: setK()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.LRNLayer.get_window_size">
<code class="descname">get_window_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.get_window_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getWindowSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the LRN window size.</p>
<p>See also: getWindowStride()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.LRNLayer.set_alpha">
<code class="descname">set_alpha</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.set_alpha" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setAlpha(float</span> <span class="pre">alpha)=0</span></code></p>
<p>Set the LRN alpha value.</p>
<p>The valid range is [-1e20, 1e20].</p>
<p>See also: getAlpha()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.LRNLayer.set_beta">
<code class="descname">set_beta</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.set_beta" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setBeta(float</span> <span class="pre">beta)=0</span></code></p>
<p>Set the LRN beta value.</p>
<p>The valid range is [0.01, 1e5f].</p>
<p>See also: getBeta()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.LRNLayer.set_k">
<code class="descname">set_k</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.set_k" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setK(float</span> <span class="pre">k)=0</span></code></p>
<p>Set the LRN K value.</p>
<p>The valid range is [1e-5, 1e10].</p>
<p>See also: getK()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.LRNLayer.set_window_size">
<code class="descname">set_window_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.set_window_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setWindowSize(int</span> <span class="pre">windowSize)=0</span></code></p>
<p>Set the LRN window size.</p>
<p>The window size must be odd and in the range of [1, 15].</p>
<p>See also: setWindowStride()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="scalelayer">
<h3>ScaleLayer<a class="headerlink" href="#scalelayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ScaleLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ScaleLayer</code><a class="headerlink" href="#tensorrt.infer.ScaleLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>A Scale layer in a network definition.</p>
<p>This layer applies a per-element computation to its input:</p>
<p><cite>output</cite> = (<cite>input*</cite> <cite>scale</cite> + <cite>shift</cite>)^ <cite>power</cite></p>
<p>The coefficients can be applied on a per-tensor, per-channel, or per-element basis.</p>
<p>note: If the number of weights is 0, then a default value is used for shift, power, and scale. The default shift is 0, the default power is 1, and the default scale is 1.</p>
<p>The output size is the same as the input size.</p>
<p>note: The input tensor for this layer is required to have a minimum of 3 dimensions.</p>
<p>See also: ScaleMode</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.get_mode">
<code class="descname">get_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.get_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getMode()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ScaleMode</span></code></p>
<p>Set the scale mode.</p>
<p>See also: setMode()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.get_power">
<code class="descname">get_power</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.get_power" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getPower()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>Get the power value.</p>
<p>See also: setPower()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.get_scale">
<code class="descname">get_scale</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.get_scale" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getScale()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>Get the scale value.</p>
<p>See also: setScale()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.get_shift">
<code class="descname">get_shift</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.get_shift" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getShift()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>Get the shift value.</p>
<p>See also: setShift()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.set_mode">
<code class="descname">set_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.set_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setMode(ScaleMode</span> <span class="pre">mode)=0</span></code></p>
<p>Set the scale mode.</p>
<p>See also: getMode()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.set_power">
<code class="descname">set_power</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.set_power" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setPower(Weights</span> <span class="pre">power)=0</span></code></p>
<p>Set the power value.</p>
<p>See also: getPower()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.set_scale">
<code class="descname">set_scale</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.set_scale" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setScale(Weights</span> <span class="pre">scale)=0</span></code></p>
<p>Set the scale value.</p>
<p>See also: getScale()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.set_shift">
<code class="descname">set_shift</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.set_shift" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setShift(Weights</span> <span class="pre">shift)=0</span></code></p>
<p>Set the shift value.</p>
<p>See also: getShift()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="scalemode">
<h3>ScaleMode<a class="headerlink" href="#scalemode" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ScaleMode">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ScaleMode</code><a class="headerlink" href="#tensorrt.infer.ScaleMode" title="Permalink to this definition">¶</a></dt>
<dd><p>Scale mode</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="softmaxlayer">
<h3>SoftmaxLayer<a class="headerlink" href="#softmaxlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.SoftmaxLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">SoftmaxLayer</code><a class="headerlink" href="#tensorrt.infer.SoftmaxLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>A Softmax layer in a network definition.</p>
<p>This layer applies a per-channel softmax to its input.</p>
<p>The output size is the same as the input size.</p>
<p>C++ includes: NvInfer.h</p>
</dd></dl>

</div>
<div class="section" id="concatenationlayer">
<h3>ConcatenationLayer<a class="headerlink" href="#concatenationlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ConcatenationLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ConcatenationLayer</code><a class="headerlink" href="#tensorrt.infer.ConcatenationLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>A concatenation layer in a network definition.</p>
<p>The output channel size is the sum of the channel sizes of the inputs. The other output sizes are the same as the other input sizes, which must all match.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.ConcatenationLayer.get_axis">
<code class="descname">get_axis</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConcatenationLayer.get_axis" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getAxis()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the axis along which concatenation occurs.</p>
<p>See also: setAxis()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConcatenationLayer.set_axis">
<code class="descname">set_axis</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConcatenationLayer.set_axis" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setAxis(int</span> <span class="pre">axis)=0</span></code></p>
<p>Set the axis along which concatenation occurs.</p>
<p>0 is the major axis (excluding the batch dimension). The default is the number of non-batch axes in the tensor minus three (e.g. for an NCHW input it would be 0), or 0 if there are fewer than 3 non-
batch axes.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>axis</strong> (<em>*</em>) – The axis along which concatenation occurs.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="deconvolutionlayer">
<h3>DeconvolutionLayer<a class="headerlink" href="#deconvolutionlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.DeconvolutionLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">DeconvolutionLayer</code><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>A deconvolution layer in a network definition.</p>
<p>The output size is defined using the formula set by INetworkDefinition::setDeconvolutionOutputDimensionsFormula().</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.get_bias_weights">
<code class="descname">get_bias_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.get_bias_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getBiasWeights()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>Get the bias weights for the deconvolution.</p>
<p>See also: getBiasWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.get_kernel_size">
<code class="descname">get_kernel_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.get_kernel_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getKernelSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>Get the HW kernel size of the deconvolution.</p>
<p>See also: setKernelSize()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.get_kernel_weights">
<code class="descname">get_kernel_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.get_kernel_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getKernelWeights()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>Get the kernel weights for the deconvolution.</p>
<p>See also: setNbGroups()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.get_nb_groups">
<code class="descname">get_nb_groups</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.get_nb_groups" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getNbGroups()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Set the number of groups for a deconvolution.</p>
<p>See also: setNbGroups()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.get_nb_output_maps">
<code class="descname">get_nb_output_maps</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.get_nb_output_maps" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getNbOutputMaps()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the number of output feature maps for the deconvolution.</p>
<p>See also: setNbOutputMaps()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.get_padding">
<code class="descname">get_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.get_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getPadding()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>Get the padding of the deconvolution.</p>
<p>See also: setPadding()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.get_stride">
<code class="descname">get_stride</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.get_stride" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getStride()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>Get the stride of the deconvolution.</p>
<p>Default: (1,1)</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.set_bias_weights">
<code class="descname">set_bias_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.set_bias_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setBiasWeights(Weights</span> <span class="pre">weights)=0</span></code></p>
<p>Set the bias weights for the deconvolution.</p>
<p>Bias is optional. To omit bias, set the count value of the weights structure to zero.</p>
<p>The bias is applied per-feature-map, so the number of weights (if non-zero) must be equal to the number of output feature maps.</p>
<p>See also: getBiasWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.set_kernel_size">
<code class="descname">set_kernel_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.set_kernel_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setKernelSize(DimsHW</span> <span class="pre">kernelSize)=0</span></code></p>
<p>Set the HW kernel size of the convolution.</p>
<p>See also: getKernelSize()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.set_kernel_weights">
<code class="descname">set_kernel_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.set_kernel_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setKernelWeights(Weights</span> <span class="pre">weights)=0</span></code></p>
<p>Set the kernel weights for the deconvolution.</p>
<p>The weights are specified as a contiguous array in <cite>CKRS</cite> order, where <cite>C</cite> the number of input channels, <cite>K</cite> the number of output feature maps, and <cite>R</cite> and <cite>S</cite> are the height and width of the filter.</p>
<p>See also: getWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.set_nb_groups">
<code class="descname">set_nb_groups</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.set_nb_groups" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setNbGroups(int</span> <span class="pre">nbGroups)=0</span></code></p>
<p>Set the number of groups for a deconvolution.</p>
<p>The input tensor channels are divided into <cite>nbGroups</cite> groups, and a deconvolution is executed for each group, using a filter per group. The results of the group convolutions are concatenated to form
the output.</p>
<p>note: When using groups in int8 mode, the size of the groups (i.e. the channel count divided by the group count) must be a multiple of 4 for both input and output.</p>
<p>Default: 1</p>
<p>See also: getNbGroups()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.set_nb_output_maps">
<code class="descname">set_nb_output_maps</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.set_nb_output_maps" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setNbOutputMaps(int</span> <span class="pre">nbOutputMaps)=0</span></code></p>
<p>Set the number of output feature maps for the deconvolution.</p>
<p>See also: getNbOutputMaps()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.set_padding">
<code class="descname">set_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.set_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setPadding(DimsHW</span> <span class="pre">padding)=0</span></code></p>
<p>Set the padding of the deconvolution.</p>
<p>The input will be zero-padded by this number of elements in the height and width directions. Padding is symmetric.</p>
<p>Default: (0,0)</p>
<p>See also: getPadding()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.set_stride">
<code class="descname">set_stride</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.set_stride" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setStride(DimsHW</span> <span class="pre">stride)=0</span></code></p>
<p>Get the stride of the deconvolution.</p>
<p>See also: setStride()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="elementwiselayer">
<h3>ElementWiseLayer<a class="headerlink" href="#elementwiselayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ElementWiseLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ElementWiseLayer</code><a class="headerlink" href="#tensorrt.infer.ElementWiseLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>A elementwise layer in a network definition.</p>
<p>This layer applies a per-element binary operation between corresponding elements of two tensors.</p>
<p>The input dimensions of the two input tensors must be equal, and the output tensor is the same size as each input.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.ElementWiseLayer.get_operation">
<code class="descname">get_operation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ElementWiseLayer.get_operation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getOperation()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ElementWiseOperation</span></code></p>
<p>Get the binary operation for the layer.</p>
<p>See also: setOperation(), ElementWiseOperation</p>
<blockquote>
<div>setBiasWeights()</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ElementWiseLayer.set_operation">
<code class="descname">set_operation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ElementWiseLayer.set_operation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setOperation(ElementWiseOperation</span> <span class="pre">type)=0</span></code></p>
<p>Set the binary operation for the layer.</p>
<p>See also: getOperation(), ElementWiseOperation</p>
<blockquote>
<div>getBiasWeights()</div></blockquote>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="elementwiseoperation">
<h3>ElementWiseOperation<a class="headerlink" href="#elementwiseoperation" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ElementWiseOperation">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ElementWiseOperation</code><a class="headerlink" href="#tensorrt.infer.ElementWiseOperation" title="Permalink to this definition">¶</a></dt>
<dd><p>Type of operation for the layer</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="shufflelayer">
<h3>ShuffleLayer<a class="headerlink" href="#shufflelayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ShuffleLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ShuffleLayer</code><a class="headerlink" href="#tensorrt.infer.ShuffleLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Layer type for shuffling data.</p>
<p>This class shuffles data by applying in sequence: a transpose operation, a reshape operation and a second transpose operation. The dimension types of the output are those of the reshape dimension.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.ShuffleLayer.get_first_transpose">
<code class="descname">get_first_transpose</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ShuffleLayer.get_first_transpose" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getFirstTranspose()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Permutation</span></code></p>
<p>Get the permutation applied by the first transpose operation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The dimension permutation applied before the reshape.</em></li>
<li><strong>See also</strong> (<em>setFirstTranspose</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ShuffleLayer.get_reshape_dimensions">
<code class="descname">get_reshape_dimensions</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ShuffleLayer.get_reshape_dimensions" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getReshapeDimensions()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Dims</span></code></p>
<p>Get the reshaped dimensions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The reshaped dimensions.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ShuffleLayer.get_second_transpose">
<code class="descname">get_second_transpose</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ShuffleLayer.get_second_transpose" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getSecondTranspose()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Permutation</span></code></p>
<p>Get the permutation applied by the second transpose operation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The dimension permutation applied after the reshape.</em></li>
<li><strong>See also</strong> (<em>setSecondTranspose</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ShuffleLayer.set_first_transpose">
<code class="descname">set_first_transpose</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ShuffleLayer.set_first_transpose" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setFirstTranspose(Permutation</span> <span class="pre">permutation)=0</span></code></p>
<p>Set the permutation applied by the first transpose operation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>permutation</strong> (<em>*</em>) – The dimension permutation applied before the reshape.</li>
<li><strong>default is the identity permutation.</strong> (<em>The</em>) – </li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ShuffleLayer.set_reshape_dimensions">
<code class="descname">set_reshape_dimensions</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ShuffleLayer.set_reshape_dimensions" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setReshapeDimensions(Dims</span> <span class="pre">dimensions)=0</span></code></p>
<p>Set the reshaped dimensions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dimensions</strong> (<em>*</em>) – The reshaped dimensions.</li>
<li><strong>special values can be used as dimensions.</strong> (<em>Two</em>) – </li>
<li><strong>0 copies the corresponding dimension from input. This special value can be used more than once in the dimensions. If number of reshape dimensions is less than input</strong><strong>, </strong><strong>0s are resolved by aligning</strong> (<em>Value</em>) – </li>
<li><strong>most significant dimensions of input.</strong> (<em>the</em>) – </li>
<li><strong>-1 infers that particular dimension by looking at input and rest of the reshape dimensions. Note that only a maximum of one dimension is permitted to be specified as -1.</strong> (<em>Value</em>) – </li>
<li><strong>product of the new dimensions must be equal to the product of the old.</strong> (<em>The</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ShuffleLayer.set_second_transpose">
<code class="descname">set_second_transpose</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ShuffleLayer.set_second_transpose" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setSecondTranspose(Permutation</span> <span class="pre">permutation)=0</span></code></p>
<p>Set the permutation applied by the second transpose operation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>permutation</strong> (<em>*</em>) – The dimension permutation applied after the reshape.</li>
<li><strong>default is the identity permutation.</strong> (<em>The</em>) – </li>
<li><strong>permutation is applied as outputDimensionIndex = permutation.order</strong><strong>[</strong><strong>inputDimensionIndex</strong><strong>]</strong><strong>, </strong><strong>so to permute from CHW order to HWC order</strong><strong>, </strong><strong>the required permutation is</strong><strong> [</strong><strong>1</strong><strong>, </strong><strong>2</strong><strong>, </strong><strong>0</strong><strong>]</strong><strong></strong> (<em>The</em>) – </li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="permutation">
<h3>Permutation<a class="headerlink" href="#permutation" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Permutation">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Permutation</code><a class="headerlink" href="#tensorrt.infer.Permutation" title="Permalink to this definition">¶</a></dt>
<dd><dl class="attribute">
<dt>
<code class="descname">* `order`</code></dt>
<dd><p><cite>int</cite> – The elements of the permutation. The permutation is applied as outputDimensionIndex = permutation.order[inputDimensionIndex], so to permute from CHW order to HWC order, the required permutation is
[1, 2, 0], and to permute from HWC to CHW, the required permutation is [2, 0, 1].</p>
</dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.Permutation.order">
<code class="descname">order</code><a class="headerlink" href="#tensorrt.infer.Permutation.order" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="unarylayer">
<h3>UnaryLayer<a class="headerlink" href="#unarylayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.UnaryLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">UnaryLayer</code><a class="headerlink" href="#tensorrt.infer.UnaryLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Layer that represents an unary operation.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.UnaryLayer.get_operation">
<code class="descname">get_operation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.UnaryLayer.get_operation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getOperation()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">UnaryOperation</span></code></p>
<p>Get the unary operation for the layer.</p>
<p>See also: setOperation(), UnaryOperation</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.UnaryLayer.set_operation">
<code class="descname">set_operation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.UnaryLayer.set_operation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setOperation(UnaryOperation</span> <span class="pre">op)=0</span></code></p>
<p>Set the unary operation for the layer.</p>
<p>See also: getOperation(), UnaryOperation</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="unaryoperation">
<h3>UnaryOperation<a class="headerlink" href="#unaryoperation" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.UnaryOperation">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">UnaryOperation</code><a class="headerlink" href="#tensorrt.infer.UnaryOperation" title="Permalink to this definition">¶</a></dt>
<dd><p>Type of operation for the layer</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="pluginlayer">
<h3>PluginLayer<a class="headerlink" href="#pluginlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.PluginLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">PluginLayer</code><a class="headerlink" href="#tensorrt.infer.PluginLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Layer type for plugins.</p>
<p>See also: IPluginExt</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.PluginLayer.get_plugin">
<code class="descname">get_plugin</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PluginLayer.get_plugin" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getPlugin()=0</span> <span class="pre">-&gt;</span> <span class="pre">IPlugin</span> <span class="pre">&amp;</span></code></p>
<p>Get the plugin for the layer.</p>
<p>See also: IPluginExt</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="paddinglayer">
<h3>PaddingLayer<a class="headerlink" href="#paddinglayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.PaddingLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">PaddingLayer</code><a class="headerlink" href="#tensorrt.infer.PaddingLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Layer that represents a padding operation.</p>
<p>The padding layer adds zero-padding at the start and end of the input tensor. It only supports padding along the two innermost dimensions. Applying negative padding results in cropping of the input.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.PaddingLayer.get_post_padding">
<code class="descname">get_post_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PaddingLayer.get_post_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getPostPadding()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>Set the padding that is applied at the end of the tensor.</p>
<p>See also: setPostPadding</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PaddingLayer.get_pre_padding">
<code class="descname">get_pre_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PaddingLayer.get_pre_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getPrePadding()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>Set the padding that is applied at the start of the tensor.</p>
<p>See also: setPrePadding</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PaddingLayer.set_post_padding">
<code class="descname">set_post_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PaddingLayer.set_post_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setPostPadding(DimsHW</span> <span class="pre">padding)=0</span></code></p>
<p>Set the padding that is applied at the end of the tensor.</p>
<p>Negative padding results in trimming the edge by the specified amount</p>
<p>See also: getPostPadding</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PaddingLayer.set_pre_padding">
<code class="descname">set_pre_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PaddingLayer.set_pre_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setPrePadding(DimsHW</span> <span class="pre">padding)=0</span></code></p>
<p>Set the padding that is applied at the start of the tensor.</p>
<p>Negative padding results in trimming the edge by the specified amount</p>
<p>See also: getPrePadding</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="rnnlayer">
<h3>RNNLayer<a class="headerlink" href="#rnnlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.RNNLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">RNNLayer</code><a class="headerlink" href="#tensorrt.infer.RNNLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>A RNN layer in a network definition.</p>
<p>This layer applies an RNN operation on the inputs.</p>
<p>Deprecated
This interface is superseded by IRNNv2Layer.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_bias">
<code class="descname">get_bias</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_bias" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getBias()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>Get the bias parameter vector for the RNN.</p>
<p>See also: setBias()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_cell_state">
<code class="descname">get_cell_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_cell_state" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getCellState()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ITensor</span> <span class="pre">*</span></code></p>
<p>Get the initial cell state of the RNN.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">nullptr if no initial cell tensor was specified, the initial cell data otherwise.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_data_length">
<code class="descname">get_data_length</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_data_length" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getDataLength()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the length of the data being processed by the RNN for use in computing other values.</p>
<p>See also: setHiddenState(), setCellState()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_direction">
<code class="descname">get_direction</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_direction" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getDirection()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">RNNDirection</span></code></p>
<p>Get the direction of the RNN layer.</p>
<p>See also: setDirection(), RNNDirection</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_hidden_size">
<code class="descname">get_hidden_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_hidden_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getHiddenSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">std::size_t</span></code></p>
<p>Get the size of the hidden layers.</p>
<p>The hidden size is the value of hiddenSize parameter passed into addRNN().</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The internal hidden layer size for the RNN.</em></li>
<li><strong>See also</strong> (<em>getDirection(), addRNN()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_hidden_state">
<code class="descname">get_hidden_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_hidden_state" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getHiddenState()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ITensor</span> <span class="pre">*</span></code></p>
<p>Get the initial hidden state of the RNN.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">nullptr if no initial hidden tensor was specified, the initial hidden data otherwise.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_input_mode">
<code class="descname">get_input_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_input_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getInputMode()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">RNNInputMode</span></code></p>
<p>Get the operation of the RNN layer.</p>
<p>See also: setInputMode(), RNNInputMode</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_layer_count">
<code class="descname">get_layer_count</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_layer_count" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getLayerCount()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">unsigned</span></code></p>
<p>Get the number of layers in the RNN.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The number of layers in the RNN.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_operation">
<code class="descname">get_operation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_operation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getOperation()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">RNNOperation</span></code></p>
<p>Get the operation of the RNN layer.</p>
<p>See also: setOperation(), RNNOperation</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_seq_length">
<code class="descname">get_seq_length</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_seq_length" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getSeqLength()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the sequence length.</p>
<p>The sequence length is the maximum number of time steps passed into the addRNN() function. This is also the maximum number of input tensors that the RNN can process at once.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the maximum number of time steps that can be executed by a single call RNN layer.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_weights">
<code class="descname">get_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getWeights()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>Get the W weights for the RNN.</p>
<p>See also: setWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.set_bias">
<code class="descname">set_bias</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.set_bias" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setBias(Weights</span> <span class="pre">bias)=0</span></code></p>
<p>Set the bias parameters for the RNN.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>bias</strong> (<em>*</em>) – The weight structure holding the bias parameters.</li>
<li><strong>trained weights for the bias parameter vectors of the RNN. The DataType for this structure must be kFLOAT</strong><strong> or </strong><strong>kHALF</strong><strong>, </strong><strong>and must be the same datatype as the input tensor.</strong> (<em>The</em>) – </li>
<li><strong>layout of the weight structure depends on the RNNOperation</strong><strong>, </strong><strong>RNNInputMode</strong><strong>, </strong><strong>and RNNDirection of the layer. The array specified by weights.values contains a sequence of bias vectors</strong><strong>, </strong><strong>where each</strong> (<em>The</em>) – </li>
<li><strong>vector is linearly appended after the previous without padding; e.g.</strong><strong>, </strong><strong>if bias vector 0 and 1 have M and N elements respectively</strong><strong>, </strong><strong>then the layout of weights.values in memory looks like</strong> (<em>bias</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>The ordering of bias vectors is similar to the ordering of weight matrices as described in setWeights(). To determine the order of bias vectors for a given RNN configuration, determine the ordered
list of weight matrices <cite>[ W0, W1, …, Wn ]</cite>. Then replace each weight matrix with its corresponding bias vector, i.e. apply the following transform (for layer <cite>l</cite>, gate <cite>g</cite>):</p>
<ul class="simple">
<li><cite>Wl[g]</cite> becomes <cite>Wbl[g]</cite></li>
<li><cite>Rl[g]</cite> becomes <cite>Rbl[g]</cite></li>
</ul>
<p>For example:</p>
<ul>
<li><p class="first">an RNN with <cite>getLayerCount() == 3</cite>, <cite>getDirection() == kUNIDIRECTION</cite>, and <cite>getOperation() == kRELU</cite> has the following order:</p>
<p><cite>[ Wb0[i], Rb0[i], Wb1[i], Rb1[i], Wb2[i], Rb2[i] ]</cite></p>
</li>
<li><p class="first">an RNN with <cite>getLayerCount() == 2</cite>, <cite>getDirection() == kUNIDIRECTION</cite>, and <cite>getOperation() == kGRU</cite> has the following order:</p>
<p><cite>[ Wb0[z], Wb0[r], Wb0[h], Rb0[z], Rb0[r], Rb0[h], Wb1[z], Wb1[r], Wb1[h], Rb1[z], Rb1[r], Rb1[h] ]</cite></p>
</li>
<li><p class="first">an RNN with <cite>getLayerCount() == 2</cite>, <cite>getDirection() == kBIDIRECTION</cite>, and <cite>getOperation() == kRELU</cite> has the following order:</p>
<p><cite>[ Wb0_fw[i], Rb0_fw[i], Wb0_bw[i], Rb0_bw[i], Wb1_fw[i], Rb1_fw[i], Wb1_bw[i], Rb1_bw[i] ]</cite></p>
<p>(fw = “forward”, bw = “backward”)</p>
</li>
</ul>
<p>Each bias vector has a fixed size, getHiddenSize().</p>
<p>See also: getBias(), RNNOperation</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.set_cell_state">
<code class="descname">set_cell_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.set_cell_state" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setCellState(ITensor</span> <span class="pre">&amp;cell)=0</span></code></p>
<p>Set the initial cell state of the RNN with the provided <cite>cell</cite> ITensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>cell</strong> (<em>*</em>) – The initial cell state of the RNN.</li>
<li><strong>layout for cell is a linear layout of a 3D matrix</strong> (<em>The</em>) – </li>
<li><strong>C - The number of layers in the RNN</strong><strong>, </strong><strong>it must match getLayerCount</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>*</em>) – </li>
<li><strong>H - The number of mini-batches for each time sequence.</strong> (<em>*</em>) – </li>
<li><strong>W - The size of the per layer hidden states</strong><strong>, </strong><strong>it must match getHiddenSize</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>*</em>) – </li>
<li><strong>cell is not specified</strong><strong>, </strong><strong>then the initial cell state is set to zero.</strong> (<em>If</em>) – </li>
<li><strong>amount of space required is doubled if getDirection</strong><strong>(</strong><strong>) </strong><strong>is kBIDIRECTION with the bidirectional states coming after the unidirectional states.</strong> (<em>The</em>) – </li>
<li><strong>cell state only affects LSTM RNN's.</strong> (<em>The</em>) – </li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.set_direction">
<code class="descname">set_direction</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.set_direction" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setDirection(RNNDirection</span> <span class="pre">op)=0</span></code></p>
<p>Set the direction of the RNN layer.</p>
<p>The direction determines if the RNN is run as a unidirectional(left to right) or bidirectional(left to right and right to left). In the kBIDIRECTION case the output is concatenated together, resulting
in output size of 2x getHiddenSize().</p>
<p>See also: getDirection(), RNNDirection</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.set_hidden_state">
<code class="descname">set_hidden_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.set_hidden_state" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setHiddenState(ITensor</span> <span class="pre">&amp;hidden)=0</span></code></p>
<p>Set the initial hidden state of the RNN with the provided <cite>hidden</cite> ITensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>hidden</strong> (<em>*</em>) – The initial hidden state of the RNN.</li>
<li><strong>layout for hidden is a linear layout of a 3D matrix</strong> (<em>The</em>) – </li>
<li><strong>C - The number of layers in the RNN</strong><strong>, </strong><strong>it must match getLayerCount</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>*</em>) – </li>
<li><strong>H - The number of mini-batches for each time sequence.</strong> (<em>*</em>) – </li>
<li><strong>W - The size of the per layer hidden states</strong><strong>, </strong><strong>it must match getHiddenSize</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>*</em>) – </li>
<li><strong>amount of space required is doubled if getDirection</strong><strong>(</strong><strong>) </strong><strong>is kBIDIRECTION with the bidirectional states coming after the unidirectional states.</strong> (<em>The</em>) – </li>
<li><strong>hidden is not specified</strong><strong>, </strong><strong>then the initial hidden state is set to zero.</strong> (<em>If</em>) – </li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.set_input_mode">
<code class="descname">set_input_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.set_input_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setInputMode(RNNInputMode</span> <span class="pre">op)=0</span></code></p>
<p>Set the operation of the RNN layer.</p>
<p>See also: getInputMode(), RNNInputMode</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.set_operation">
<code class="descname">set_operation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.set_operation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setOperation(RNNOperation</span> <span class="pre">op)=0</span></code></p>
<p>Set the operation of the RNN layer.</p>
<p>See also: getOperation(), RNNOperation</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.set_weights">
<code class="descname">set_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.set_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">setWeights(Weights</span> <span class="pre">weights)=0</span></code></p>
<p>Set the weight parameters for the RNN.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>weights</strong> (<em>*</em>) – The weight structure holding the weight parameters.</li>
<li><strong>trained weights for the weight parameter matrices of the RNN. The DataType for this structure must be kFLOAT</strong><strong> or </strong><strong>kHALF</strong><strong>, </strong><strong>and must be the same datatype as the input tensor.</strong> (<em>The</em>) – </li>
<li><strong>layout of the weight structure depends on the RNNOperation</strong><strong>, </strong><strong>RNNInputMode</strong><strong>, </strong><strong>and RNNDirection of the layer. The array specified by weights.values contains a sequence of parameter matrices</strong><strong>, </strong><strong>where</strong> (<em>The</em>) – </li>
<li><strong>parameter matrix is linearly appended after the previous without padding; e.g.</strong><strong>, </strong><strong>if parameter matrix 0 and 1 have M and N elements respectively</strong><strong>, </strong><strong>then the layout of weights.values in memory looks</strong> (<em>each</em>) – </li>
<li><strong>like</strong> – </li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>The following sections describe the order of weight matrices and the layout of elements within a weight matrix.
Order of weight matrices
The parameter matrices are ordered as described below:</p>
<p>For example:</p>
<ul>
<li><p class="first">an RNN with <cite>getLayerCount() == 3</cite>, <cite>getDirection() == kUNIDIRECTION</cite>, and <cite>getOperation() == kRELU</cite> has the following order:</p>
<p><cite>[ W0[i], R0[i], W1[i], R1[i], W2[i], R2[i] ]</cite></p>
</li>
<li><p class="first">an RNN with <cite>getLayerCount() == 2</cite>, <cite>getDirection() == kUNIDIRECTION</cite>, and <cite>getOperation() == kGRU</cite> has the following order:</p>
<p><cite>[ W0[z], W0[r], W0[h], R0[z], R0[r], R0[h], W1[z], W1[r], W1[h], R1[z], R1[r], R1[h] ]</cite></p>
</li>
<li><p class="first">an RNN with <cite>getLayerCount() == 2</cite>, <cite>getDirection() == kBIDIRECTION</cite>, and <cite>getOperation() == kRELU</cite> has the following order:</p>
<p><cite>[ W0_fw[i], R0_fw[i], W0_bw[i], R0_bw[i], W1_fw[i], R1_fw[i], W1_bw[i], R1_bw[i] ]</cite></p>
<p>(fw = “forward”, bw = “backward”)</p>
</li>
</ul>
<p>Layout of elements within a weight matrix
Each parameter matrix is row-major in memory, and has the following dimensions:</p>
<p>In other words, the input weights of the first layer of the RNN (if not skipped) transform a <cite>getDataLength()</cite>-size column vector into a <cite>getHiddenSize()</cite>-size column vector. The input weights of
subsequent layers transform a <cite>K*getHiddenSize()</cite>-size column vector into a <cite>getHiddenSize()</cite>-size column vector. <cite>K=2</cite> in the bidirectional case to account for the full hidden state being the
concatenation of the forward and backward RNN hidden states.</p>
<p>The recurrent weight matrices for all layers all have shape <cite>(H, H)</cite>, both in the unidirectional and bidirectional cases. (In the bidirectional case, each recurrent weight matrix for the (forward or
backward) RNN cell operates on the previous (forward or backward) RNN cell’s hidden state, which is size <cite>H</cite>).</p>
<p>See also: getWeights(), RNNOperation</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="rnnoperation">
<h3>RNNOperation<a class="headerlink" href="#rnnoperation" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.RNNOperation">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">RNNOperation</code><a class="headerlink" href="#tensorrt.infer.RNNOperation" title="Permalink to this definition">¶</a></dt>
<dd><p>Type of operation for the layer</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="rnndirection">
<h3>RNNDirection<a class="headerlink" href="#rnndirection" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.RNNDirection">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">RNNDirection</code><a class="headerlink" href="#tensorrt.infer.RNNDirection" title="Permalink to this definition">¶</a></dt>
<dd><p>Direction for the RNN Layer</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="rnninputmode">
<h3>RNNInputMode<a class="headerlink" href="#rnninputmode" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.RNNInputMode">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">RNNInputMode</code><a class="headerlink" href="#tensorrt.infer.RNNInputMode" title="Permalink to this definition">¶</a></dt>
<dd><p>Input mode for RNN Layer</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
</div>
<div class="section" id="int8-calibration">
<h2>Int8 Calibration<a class="headerlink" href="#int8-calibration" title="Permalink to this headline">¶</a></h2>
<div class="section" id="int8calibrator">
<h3>Int8Calibrator<a class="headerlink" href="#int8calibrator" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Int8Calibrator">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Int8Calibrator</code><a class="headerlink" href="#tensorrt.infer.Int8Calibrator" title="Permalink to this definition">¶</a></dt>
<dd><p>Application-implemented interface for calibration.</p>
<p>Calibration is a step performed by the builder when deciding suitable scale factors for 8-bit inference.</p>
<p>It must also provide a method for retrieving representative images which the calibration process can use to examine the distribution of activations. It may optionally implement a method for caching
the calibration result for reuse on subsequent runs.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Int8Calibrator.get_algorithm">
<code class="descname">get_algorithm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8Calibrator.get_algorithm" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getAlgorithm()=0</span> <span class="pre">-&gt;</span> <span class="pre">CalibrationAlgoType</span></code></p>
<p>Get the algorithm used by this calibrator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The algorithm used by the calibrator.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8Calibrator.get_batch">
<code class="descname">get_batch</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8Calibrator.get_batch" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getBatch(void</span> <span class="pre">*bindings[],</span> <span class="pre">const</span> <span class="pre">char</span> <span class="pre">*names[],</span> <span class="pre">int</span> <span class="pre">nbBindings)=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>Get a batch of input for calibration.</p>
<p>The batch size of the input must match the batch size returned by getBatchSize().</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>bindings</strong> (<em>*</em>) – An array of pointers to device memory that must be set to the memory containing each network input data.</li>
<li><strong>names</strong> (<em>*</em>) – The names of the network input for each pointer in the binding array.</li>
<li><strong>nbBindings</strong> (<em>*</em>) – The number of pointers in the bindings array.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>False if there are no more batches for calibration.</em></li>
<li><strong>See also</strong> (<em>getBatchSize()</em>)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8Calibrator.get_batch_size">
<code class="descname">get_batch_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8Calibrator.get_batch_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getBatchSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>Get the batch size used for calibration batches.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The batch size.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8Calibrator.read_calibration_cache">
<code class="descname">read_calibration_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8Calibrator.read_calibration_cache" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">readCalibrationCache(std::size_t</span> <span class="pre">&amp;length)=0</span> <span class="pre">-&gt;</span> <span class="pre">const</span> <span class="pre">void</span> <span class="pre">*</span></code></p>
<p>Load a calibration cache.</p>
<p>Calibration is potentially expensive, so it can be useful to generate the calibration data once, then use it on subsequent builds of the network. The cache includes the regression cutoff and quantile
values used to generate it, and will not be used if these do not batch the settings of the current calibrator. However, the network should also be recalibrated if its structure changes, or the input
data set changes, and it is the responsibility of the application to ensure this.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>length</strong> (<em>*</em>) – The length of the cached data, that should be set by the called function. If there is no data, this should be zero.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">A pointer to the cache, or nullptr if there is no data.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8Calibrator.write_calibration_cache">
<code class="descname">write_calibration_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8Calibrator.write_calibration_cache" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">writeCalibrationCache(const</span> <span class="pre">void</span> <span class="pre">*ptr,</span> <span class="pre">std::size_t</span> <span class="pre">length)=0</span></code></p>
<p>Save a calibration cache.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>ptr</strong> (<em>*</em>) – A pointer to the data to cache.</li>
<li><strong>length</strong> (<em>*</em>) – The length in bytes of the data to cache.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="int8entropycalibrator">
<h3>Int8EntropyCalibrator<a class="headerlink" href="#int8entropycalibrator" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Int8EntropyCalibrator">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Int8EntropyCalibrator</code><a class="headerlink" href="#tensorrt.infer.Int8EntropyCalibrator" title="Permalink to this definition">¶</a></dt>
<dd><p>Entropy calibrator. This is the preferred calibrator, as it is less complicated than the legacy calibrator and produces better results.</p>
<p>C++ includes: NvInfer.h</p>
</dd></dl>

</div>
<div class="section" id="int8legacycalibrator">
<h3>Int8LegacyCalibrator<a class="headerlink" href="#int8legacycalibrator" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Int8LegacyCalibrator">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Int8LegacyCalibrator</code><a class="headerlink" href="#tensorrt.infer.Int8LegacyCalibrator" title="Permalink to this definition">¶</a></dt>
<dd><p>Legacy calibrator for compatibility with 2.0 EA. Will be removed in 2.2. Deprecated</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Int8LegacyCalibrator.get_algorithm">
<code class="descname">get_algorithm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8LegacyCalibrator.get_algorithm" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getAlgorithm()</span> <span class="pre">-&gt;</span> <span class="pre">CalibrationAlgoType</span></code></p>
<p>Signal that this is the legacy calibrator.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8LegacyCalibrator.get_quantile">
<code class="descname">get_quantile</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8LegacyCalibrator.get_quantile" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getQuantile()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">double</span></code></p>
<p>The quantile (between 0 and 1) that will be used to select the region maximum when the quantile method is in use.</p>
<p>See the user guide for more details on how the quantile is used.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8LegacyCalibrator.get_regression_cutoff">
<code class="descname">get_regression_cutoff</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8LegacyCalibrator.get_regression_cutoff" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">getRegressionCutoff()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">double</span></code></p>
<p>The fraction (between 0 and 1) of the maximum used to define the regression cutoff when using regression to determine the region maximum.</p>
<p>See the user guide for more details on how the regression cutoff is used</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8LegacyCalibrator.read_histogram_cache">
<code class="descname">read_histogram_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8LegacyCalibrator.read_histogram_cache" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">readHistogramCache(std::size_t</span> <span class="pre">&amp;length)=0</span> <span class="pre">-&gt;</span> <span class="pre">const</span> <span class="pre">void</span> <span class="pre">*</span></code></p>
<p>Load a histogram.</p>
<p>Histogram generation is potentially expensive, so it can be useful to generate the histograms once, then use them when exploring the space of calibrations. The histograms should be regenerated if the
network structure changes, or the input data set changes, and it is the responsibility of the application to ensure this.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>length</strong> (<em>*</em>) – The length of the cached data, that should be set by the called function. If there is no data, this should be zero.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">A pointer to the cache, or nullptr if there is no data.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8LegacyCalibrator.write_histogram_cache">
<code class="descname">write_histogram_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8LegacyCalibrator.write_histogram_cache" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">writeHistogramCache(const</span> <span class="pre">void</span> <span class="pre">*ptr,</span> <span class="pre">std::size_t</span> <span class="pre">length)=0</span></code></p>
<p>Save a histogram cache.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>ptr</strong> (<em>*</em>) – A pointer to the data to cache.</li>
<li><strong>length</strong> (<em>*</em>) – The length in bytes of the data to cache.</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="calibrationalgotype">
<h3>CalibrationAlgoType<a class="headerlink" href="#calibrationalgotype" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.CalibrationAlgoType">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">CalibrationAlgoType</code><a class="headerlink" href="#tensorrt.infer.CalibrationAlgoType" title="Permalink to this definition">¶</a></dt>
<dd><p>Type of int8 calibration algorithm</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
</div>
<div class="section" id="logger">
<h2>Logger<a class="headerlink" href="#logger" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3>Logger<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Logger">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Logger</code><a class="headerlink" href="#tensorrt.infer.Logger" title="Permalink to this definition">¶</a></dt>
<dd><p>Application-implemented logging interface for the builder, engine and runtime.</p>
<p>Note that although a logger is passed on creation to each instance of a IBuilder or IRuntime interface, the logger is internally considered a singleton, and thus multiple instances of IRuntime and/or
IBuilder must all use the same logger.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Logger.log">
<code class="descname">log</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Logger.log" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">log(Severity</span> <span class="pre">severity,</span> <span class="pre">const</span> <span class="pre">char</span> <span class="pre">*msg)=0</span></code></p>
<p>A callback implemented by the application to handle logging messages;</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>severity</strong> (<em>*</em>) – The severity of the message.</li>
<li><strong>msg</strong> (<em>*</em>) – The log message, null terminated.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="consolelogger">
<h3>ConsoleLogger<a class="headerlink" href="#consolelogger" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ConsoleLogger">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ConsoleLogger</code><a class="headerlink" href="#tensorrt.infer.ConsoleLogger" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="tensorrt.infer.ConsoleLogger.log">
<code class="descname">log</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConsoleLogger.log" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">log(Severity</span> <span class="pre">severity,</span> <span class="pre">const</span> <span class="pre">char</span> <span class="pre">*msg)=0</span></code></p>
<p>A callback implemented by the application to handle logging messages;</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>severity</strong> (<em>*</em>) – The severity of the message.</li>
<li><strong>msg</strong> (<em>*</em>) – The log message, null terminated.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="logseverity">
<h3>LogSeverity<a class="headerlink" href="#logseverity" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.LogSeverity">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">LogSeverity</code><a class="headerlink" href="#tensorrt.infer.LogSeverity" title="Permalink to this definition">¶</a></dt>
<dd><p>Log level specifier</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
</div>
<div class="section" id="profiler">
<h2>Profiler<a class="headerlink" href="#profiler" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id2">
<h3>Profiler<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Profiler">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Profiler</code><a class="headerlink" href="#tensorrt.infer.Profiler" title="Permalink to this definition">¶</a></dt>
<dd><p>Application-implemented interface for profiling.</p>
<p>When this class is added to an execution context, the profiler will be called once per layer for each invocation of execute(). Note that enqueue() does not currently support profiling.</p>
<p>The profiler will only be called after execution is complete. It has a small impact on execution time.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Profiler.report_layer_time">
<code class="descname">report_layer_time</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Profiler.report_layer_time" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">reportLayerTime(const</span> <span class="pre">char</span> <span class="pre">*layerName,</span> <span class="pre">float</span> <span class="pre">ms)=0</span></code></p>
<p>Layer time reporting callback.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>layerName</strong> (<em>*</em>) – The name of the layer, set when constructing the network definition.</li>
<li><strong>ms</strong> (<em>*</em>) – The time in milliseconds to execute the layer.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="consoleprofiler">
<h3>ConsoleProfiler<a class="headerlink" href="#consoleprofiler" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ConsoleProfiler">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ConsoleProfiler</code><a class="headerlink" href="#tensorrt.infer.ConsoleProfiler" title="Permalink to this definition">¶</a></dt>
<dd><dl class="attribute">
<dt id="tensorrt.infer.ConsoleProfiler.mProfile">
<code class="descname">mProfile</code><a class="headerlink" href="#tensorrt.infer.ConsoleProfiler.mProfile" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConsoleProfiler.report_layer_time">
<code class="descname">report_layer_time</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConsoleProfiler.report_layer_time" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">reportLayerTime(const</span> <span class="pre">char</span> <span class="pre">*layerName,</span> <span class="pre">float</span> <span class="pre">ms)=0</span></code></p>
<p>Layer time reporting callback.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>layerName</strong> (<em>*</em>) – The name of the layer, set when constructing the network definition.</li>
<li><strong>ms</strong> (<em>*</em>) – The time in milliseconds to execute the layer.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.ConsoleProfiler.timing_iterations">
<code class="descname">timing_iterations</code><a class="headerlink" href="#tensorrt.infer.ConsoleProfiler.timing_iterations" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="utils.html" class="btn btn-neutral float-right" title="tensorrt.utils" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../workflows/manually_construct_tensorrt_engine.html" class="btn btn-neutral" title="Manually Constructing a TensorRT Engine" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, NVIDIA Corporation.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'4.0',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          
          SphinxRtdTheme.Navigation.enableSticky();
          
      });
  </script> 

</body>
</html>